{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import time\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 19)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('/Users/nitanshjain/Documents/Thapar 4th Sem/Machine Learing/Machine_Learning_Project/data/final_manual_priority.csv')\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.no.</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>twt_created_at</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>nltk_compound</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>nltk_sentiment</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>UtkarshMishra_9</td>\n",
       "      <td>Noida, India</td>\n",
       "      <td>707</td>\n",
       "      <td>1122</td>\n",
       "      <td>2022-11-08 21:14:55+00:00</td>\n",
       "      <td>5764</td>\n",
       "      <td>0</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>[{'text': 'earthquake', 'indices': [137, 148]}...</td>\n",
       "      <td>[{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>GirjeshKPatel</td>\n",
       "      <td>‚Ä°¬ß‚â§‚Ä°¬ß√±‚Ä°¬ß¬Æ‚Ä°¬ß√§, ‚Ä°¬ß‚â†‚Ä°¬ß√¶...</td>\n",
       "      <td>164</td>\n",
       "      <td>988</td>\n",
       "      <td>2022-11-08 20:54:48+00:00</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>heavy roorke uttrakhand second horrible moment</td>\n",
       "      <td>[{'text': 'earthquake', 'indices': [6, 17]}]</td>\n",
       "      <td>[{'screen_name': 'ZeeNews', 'name': 'Zee News'...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>TheAnantpandit</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>409</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-11-08 20:46:16+00:00</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake magnitude occurred ist lat long dep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'Indiametdept', 'name': 'Indi...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>kanhagupta21</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>182</td>\n",
       "      <td>13</td>\n",
       "      <td>2022-11-08 20:38:44+00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>horrible ended running outside home safe</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>Kunalgupta_voi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-08 20:10:38+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>choking wakeup antismog gun installed watering...</td>\n",
       "      <td>[{'text': 'DelhiPollution', 'indices': [253, 2...</td>\n",
       "      <td>[{'screen_name': 'ArvindKejriwal', 'name': 'Ar...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.6597</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.no.  user_id  tweet_id         username  \\\n",
       "0      4       11        11  UtkarshMishra_9   \n",
       "1      8       18        18    GirjeshKPatel   \n",
       "2     10       25        25   TheAnantpandit   \n",
       "3     11       31        31     kanhagupta21   \n",
       "4     13       42        42   Kunalgupta_voi   \n",
       "\n",
       "                                            location  following  followers  \\\n",
       "0                                       Noida, India        707       1122   \n",
       "1  ‚Ä°¬ß‚â§‚Ä°¬ß√±‚Ä°¬ß¬Æ‚Ä°¬ß√§, ‚Ä°¬ß‚â†‚Ä°¬ß√¶...        164        988   \n",
       "2                                   New Delhi, India        409         19   \n",
       "3                                          Allahabad        182         13   \n",
       "4                                                NaN         21          1   \n",
       "\n",
       "              twt_created_at  total_tweets  retweet_count  \\\n",
       "0  2022-11-08 21:14:55+00:00          5764              0   \n",
       "1  2022-11-08 20:54:48+00:00           522              0   \n",
       "2  2022-11-08 20:46:16+00:00           152              0   \n",
       "3  2022-11-08 20:38:44+00:00            73              0   \n",
       "4  2022-11-08 20:10:38+00:00             1              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  estimated magnitude earthquake affected countr...   \n",
       "1     heavy roorke uttrakhand second horrible moment   \n",
       "2  earthquake magnitude occurred ist lat long dep...   \n",
       "3           horrible ended running outside home safe   \n",
       "4  choking wakeup antismog gun installed watering...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'earthquake', 'indices': [137, 148]}...   \n",
       "1       [{'text': 'earthquake', 'indices': [6, 17]}]   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{'text': 'DelhiPollution', 'indices': [253, 2...   \n",
       "\n",
       "                                            mentions  textblob_polarity  \\\n",
       "0  [{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...           0.000000   \n",
       "1  [{'screen_name': 'ZeeNews', 'name': 'Zee News'...          -0.400000   \n",
       "2  [{'screen_name': 'Indiametdept', 'name': 'Indi...          -0.050000   \n",
       "3  [{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...          -0.166667   \n",
       "4  [{'screen_name': 'ArvindKejriwal', 'name': 'Ar...           0.000000   \n",
       "\n",
       "   nltk_compound  avg_sentiment  textblob_sentiment  nltk_sentiment  priority  \n",
       "0        -0.1531             -1                   0              -1         0  \n",
       "1        -0.5423             -1                  -1              -1         1  \n",
       "2         0.0000             -1                  -1               0         0  \n",
       "3        -0.1531             -1                  -1              -1         1  \n",
       "4        -0.6597             -1                   0              -1         1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping user_id, username, location, following, followers, twt_created_at, total_tweets, retweet_count, hashtags, mentions, tweet_id_dup\n",
    "tweets_df.drop(['S.no.', 'user_id', 'username', 'location', 'following', 'followers', 'twt_created_at', 'total_tweets', 'retweet_count', 'hashtags', 'mentions', 'textblob_polarity', 'nltk_compound', 'textblob_sentiment', 'nltk_sentiment', 'avg_sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'text', 'priority'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>heavy roorke uttrakhand second horrible moment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>earthquake magnitude occurred ist lat long dep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>horrible ended running outside home safe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>choking wakeup antismog gun installed watering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  priority\n",
       "0        11  estimated magnitude earthquake affected countr...         0\n",
       "1        18     heavy roorke uttrakhand second horrible moment         1\n",
       "2        25  earthquake magnitude occurred ist lat long dep...         0\n",
       "3        31           horrible ended running outside home safe         1\n",
       "4        42  choking wakeup antismog gun installed watering...         1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    109\n",
       "0     89\n",
       "Name: priority, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['priority'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_tokens(df):\n",
    "    tokens = list()\n",
    "    tokenizer = TweetTokenizer()\n",
    "    \n",
    "    for tweets in df.loc[:, 'text']:\n",
    "        # print(len(tokenizer.tokenize(tweets)))\n",
    "        tokens.append(tokenizer.tokenize(tweets))\n",
    "    \n",
    "    df['tokens'] = tokens\n",
    "    \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    # Get the stemmed_tokens\n",
    "    df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df['tokens']]\n",
    "    df['stemmed_tokens'].head(10)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>priority</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[estimated, magnitude, earthquake, affected, c...</td>\n",
       "      <td>[estim, magnitud, earthquak, affect, countri, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>heavy roorke uttrakhand second horrible moment</td>\n",
       "      <td>1</td>\n",
       "      <td>[heavy, roorke, uttrakhand, second, horrible, ...</td>\n",
       "      <td>[heavi, roork, uttrakhand, second, horribl, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>earthquake magnitude occurred ist lat long dep...</td>\n",
       "      <td>0</td>\n",
       "      <td>[earthquake, magnitude, occurred, ist, lat, lo...</td>\n",
       "      <td>[earthquak, magnitud, occur, ist, lat, long, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>horrible ended running outside home safe</td>\n",
       "      <td>1</td>\n",
       "      <td>[horrible, ended, running, outside, home, safe]</td>\n",
       "      <td>[horribl, end, run, outsid, home, safe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>choking wakeup antismog gun installed watering...</td>\n",
       "      <td>1</td>\n",
       "      <td>[choking, wakeup, antismog, gun, installed, wa...</td>\n",
       "      <td>[choke, wakeup, antismog, gun, instal, water, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  priority  \\\n",
       "0        11  estimated magnitude earthquake affected countr...         0   \n",
       "1        18     heavy roorke uttrakhand second horrible moment         1   \n",
       "2        25  earthquake magnitude occurred ist lat long dep...         0   \n",
       "3        31           horrible ended running outside home safe         1   \n",
       "4        42  choking wakeup antismog gun installed watering...         1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [estimated, magnitude, earthquake, affected, c...   \n",
       "1  [heavy, roorke, uttrakhand, second, horrible, ...   \n",
       "2  [earthquake, magnitude, occurred, ist, lat, lo...   \n",
       "3    [horrible, ended, running, outside, home, safe]   \n",
       "4  [choking, wakeup, antismog, gun, installed, wa...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  [estim, magnitud, earthquak, affect, countri, ...  \n",
       "1  [heavi, roork, uttrakhand, second, horribl, mo...  \n",
       "2  [earthquak, magnitud, occur, ist, lat, long, d...  \n",
       "3            [horribl, end, run, outsid, home, safe]  \n",
       "4  [choke, wakeup, antismog, gun, instal, water, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = creating_tokens(tweets_df)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df['stemmed_tokens'], df['priority'], test_size=test_size, random_state=42, stratify=df['priority'])\n",
    "    \n",
    "    print(y_train.value_counts())\n",
    "    print(y_test.value_counts())\n",
    "    # print(type(x_train))\n",
    "    # print(type(y_train))\n",
    "    \n",
    "    x_train = x_train.to_frame()\n",
    "    x_train = x_train.reset_index()\n",
    "    \n",
    "    x_test = x_test.to_frame()\n",
    "    x_test = x_test.reset_index()\n",
    "    \n",
    "    y_train = y_train.to_frame()\n",
    "    y_train = y_train.reset_index()\n",
    "    \n",
    "    y_test = y_test.to_frame()\n",
    "    y_test = y_test.reset_index()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    76\n",
      "0    62\n",
      "Name: priority, dtype: int64\n",
      "1    33\n",
      "0    27\n",
      "Name: priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(tweets_df, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                     stemmed_tokens\n",
      "0    164  [forgiv, rapist, murder, cruel, enter, mandir,...\n",
      "1     36  [socha, puch, illeg, resort, demolish, still, ...\n",
      "2     92  [todai, whole, year, complet, dai, written, pa...\n",
      "3     42  [see, ground, realiti, statu, sardar, pathet, ...\n",
      "4     50  [dirti, monei, aap, need, investig, lie, detec...\n",
      "   index                                     stemmed_tokens\n",
      "0    188  [hai, chor, sath, deta, hai, pich, leta, hai, ...\n",
      "1     23  [travel, pass, markundi, toll, acp, toll, pvt,...\n",
      "2    174  [final, todai, yet, mcd, remov, broken, bench,...\n",
      "3     73  [crore, public, monei, invest, project, clean,...\n",
      "4    152  [histor, judgement, suprem, court, put, stamp,...\n",
      "   index  priority\n",
      "0    164         0\n",
      "1     36         0\n",
      "2     92         0\n",
      "3     42         1\n",
      "4     50         0\n",
      "   index  priority\n",
      "0    188         1\n",
      "1     23         1\n",
      "2    174         0\n",
      "3     73         1\n",
      "4    152         0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "print(x_test.head())\n",
    "print(y_train.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 0.20366311073303223\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "OUTPUT_FOLDER = '/Users/nitanshjain/Documents/Thapar 4th Sem/Machine Learing/Machine_Learning_Project/'\n",
    "\n",
    "start_time = time.time()\n",
    "tokens = pd.Series(tweets_df['stemmed_tokens']).values\n",
    "# print(tokens)\n",
    "word2vec_model_file = OUTPUT_FOLDER + 'word2vec_priority' + str(200) + '.model'\n",
    "\n",
    "w2v_model = Word2Vec(tokens, min_count=1, vector_size=200, window=8, workers=7, sg=3)\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\n",
    "w2v_model.save(word2vec_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(create_file, model_file, x):\n",
    "    sg_w2v_model = Word2Vec.load(model_file)\n",
    "    \n",
    "    with open(create_file, 'w+') as word2vec_file:\n",
    "        for index, row in x.iterrows():\n",
    "            model_vector = (np.mean([sg_w2v_model.wv[token] for token in row['stemmed_tokens']], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(200))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            \n",
    "            if type(model_vector) is list:\n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(200)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "    \n",
    "    df = pd.read_csv(create_file)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-0.000683</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>-0.001829</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>-0.002011</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>-0.001288</td>\n",
       "      <td>-0.001960</td>\n",
       "      <td>0.003513</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>-0.001403</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>-0.002829</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>-0.000732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000347</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>-0.003617</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.004398</td>\n",
       "      <td>-0.002802</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>-0.002669</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>-0.003966</td>\n",
       "      <td>-0.000804</td>\n",
       "      <td>-0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000556</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>-0.002480</td>\n",
       "      <td>-0.001213</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>-0.003171</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>-0.003116</td>\n",
       "      <td>-0.000339</td>\n",
       "      <td>0.001023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.001485</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>-0.004497</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>-0.002305</td>\n",
       "      <td>0.002547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>-0.004256</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>-0.003826</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>-0.005090</td>\n",
       "      <td>-0.002272</td>\n",
       "      <td>-0.000429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000638  0.000772  0.000872  0.002585  0.001369 -0.000683 -0.000171   \n",
       "1  0.000644  0.000996  0.000082  0.002669  0.001502 -0.001288 -0.001960   \n",
       "2  0.000347 -0.000391  0.001353  0.002739  0.003886 -0.003617  0.000627   \n",
       "3 -0.000556 -0.000983  0.000412  0.002801  0.003366 -0.002480 -0.001213   \n",
       "4  0.000443  0.000362  0.001485  0.005043  0.004761 -0.004497 -0.000259   \n",
       "\n",
       "          7         8         9  ...       190       191       192       193  \\\n",
       "0  0.001276 -0.000407  0.001717  ...  0.001726 -0.001953 -0.000707 -0.001829   \n",
       "1  0.003513 -0.001415  0.004125  ...  0.002600 -0.001403 -0.001382 -0.001717   \n",
       "2  0.004398 -0.002802  0.001932  ...  0.002224 -0.003431 -0.001322 -0.002669   \n",
       "3  0.002929 -0.001465  0.002784  ...  0.001999 -0.003171  0.000053 -0.002314   \n",
       "4  0.006412 -0.002305  0.002547  ...  0.003758 -0.004256 -0.000566 -0.003826   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.001028  0.002074  0.000339 -0.002011  0.000067 -0.000049  \n",
       "1  0.002783  0.002223  0.000329 -0.002829  0.000520 -0.000732  \n",
       "2  0.003696  0.000559  0.000296 -0.003966 -0.000804 -0.000751  \n",
       "3  0.003037  0.002208  0.000873 -0.003116 -0.000339  0.001023  \n",
       "4  0.002803  0.004777  0.000540 -0.005090 -0.002272 -0.000429  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_train_filename = OUTPUT_FOLDER + 'word2vec_train_priority' + str(200) + '.csv'\n",
    "word2vec_train_df = create_file(word2vec_train_filename, word2vec_model_file, x_train)\n",
    "print(word2vec_train_df.shape)\n",
    "word2vec_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000391</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>-0.003476</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>-0.002794</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>-0.004149</td>\n",
       "      <td>-0.001546</td>\n",
       "      <td>-0.004790</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>-0.004625</td>\n",
       "      <td>-0.001515</td>\n",
       "      <td>0.000891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>-0.000542</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>-0.002888</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>-0.002106</td>\n",
       "      <td>-0.000862</td>\n",
       "      <td>0.001031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000996</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>-0.002178</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>-0.002543</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.002200</td>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.002576</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000063</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>0.000612</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>-0.001472</td>\n",
       "      <td>-0.000966</td>\n",
       "      <td>0.004367</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>-0.003026</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.000447</td>\n",
       "      <td>-0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>-0.002987</td>\n",
       "      <td>-0.000252</td>\n",
       "      <td>0.003833</td>\n",
       "      <td>-0.002494</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000773</td>\n",
       "      <td>-0.002993</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.002974</td>\n",
       "      <td>0.001893</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.001819</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000391 -0.000852  0.001120  0.004581  0.003083 -0.003476  0.000676   \n",
       "1  0.000784  0.000684  0.001435  0.002856  0.002304 -0.001798 -0.000542   \n",
       "2 -0.000996  0.001554  0.000850  0.003801  0.002613 -0.002178 -0.000713   \n",
       "3 -0.000063 -0.000919  0.000612  0.003401  0.004513 -0.001472 -0.000966   \n",
       "4  0.000270  0.000614  0.001371  0.000918  0.003644 -0.002987 -0.000252   \n",
       "\n",
       "          7         8         9  ...       190       191       192       193  \\\n",
       "0  0.004705 -0.002794  0.002152  ...  0.001359 -0.004149 -0.001546 -0.004790   \n",
       "1  0.002502 -0.001741  0.001353  ...  0.001797 -0.002888 -0.001447 -0.001975   \n",
       "2  0.003097 -0.000857  0.003220  ...  0.001431 -0.002543 -0.000391 -0.002200   \n",
       "3  0.004367 -0.000720  0.002222  ...  0.001283 -0.003026 -0.000391 -0.002425   \n",
       "4  0.003833 -0.002494  0.002543  ...  0.000773 -0.002993  0.001154 -0.001238   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.002363  0.002791  0.000607 -0.004625 -0.001515  0.000891  \n",
       "1  0.001432  0.001059  0.000344 -0.002106 -0.000862  0.001031  \n",
       "2  0.002228  0.002687  0.000906 -0.002576  0.000031  0.000341  \n",
       "3  0.002589  0.001010  0.000417 -0.004035 -0.000447 -0.000616  \n",
       "4  0.002974  0.001893 -0.000023 -0.001819 -0.000207 -0.000664  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_test_filename = OUTPUT_FOLDER + 'word2vec_test_priority' + str(200) + '.csv'\n",
    "word2vec_test_df = create_file(word2vec_test_filename, word2vec_model_file, x_test)\n",
    "print(word2vec_test_df.shape)\n",
    "word2vec_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 2)\n",
      "(60, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 0.023982763290405273\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_decision_word2vec = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model\n",
    "clf_decision_word2vec.fit(word2vec_train_df, y_train['priority'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.52      0.54        27\n",
      "           1       0.63      0.67      0.65        33\n",
      "\n",
      "    accuracy                           0.60        60\n",
      "   macro avg       0.59      0.59      0.59        60\n",
      "weighted avg       0.60      0.60      0.60        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "        \n",
    "y_pred_word2vec = clf_decision_word2vec.predict(word2vec_test_df)\n",
    "print(classification_report(y_test['priority'], y_pred_word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random Forest Classifier*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 0.5915660858154297\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_Random_Forest_Classifier = RandomForestClassifier(n_estimators = 100) \n",
    " \n",
    "clf_Random_Forest_Classifier.fit(word2vec_train_df, y_train['priority'])\n",
    " \n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.48      0.57        27\n",
      "           1       0.66      0.82      0.73        33\n",
      "\n",
      "    accuracy                           0.67        60\n",
      "   macro avg       0.67      0.65      0.65        60\n",
      "weighted avg       0.67      0.67      0.66        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_randomforest = clf_Random_Forest_Classifier.predict(word2vec_test_df)\n",
    "\n",
    "print(classification_report(y_test['priority'], y_pred_randomforest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Multinomial Gaussian Naive Bayes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 0.7547149658203125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_GNB = GaussianNB()\n",
    "clf_GNB.fit(word2vec_train_df, y_train['priority'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.74      0.65        27\n",
      "           1       0.72      0.55      0.62        33\n",
      "\n",
      "    accuracy                           0.63        60\n",
      "   macro avg       0.65      0.64      0.63        60\n",
      "weighted avg       0.65      0.63      0.63        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_GNB = clf_GNB.predict(word2vec_test_df)\n",
    "\n",
    "print(classification_report(y_test['priority'], y_pred_GNB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
