{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning specialisation coursera \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(651, 18)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('data/sentiment.csv')\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>twt_created_at</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>nltk_compound</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>nltk_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pspatilsbi</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>325</td>\n",
       "      <td>25</td>\n",
       "      <td>2022-11-08 22:08:44+00:00</td>\n",
       "      <td>2704</td>\n",
       "      <td>0</td>\n",
       "      <td>agenda great old god blees end</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'INCIndia', 'name': 'Congress...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ththegde</td>\n",
       "      <td>Kandivali East, Mumbai</td>\n",
       "      <td>582</td>\n",
       "      <td>57</td>\n",
       "      <td>2022-11-08 22:00:49+00:00</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>please allow citizen buy forex investment like...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'PMOIndia', 'name': 'PMO Indi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>rupz_boruah</td>\n",
       "      <td>Chabua, India</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>2022-11-08 21:54:37+00:00</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>please take necessary action neurologist amc d...</td>\n",
       "      <td>[{'text': 'Dr_Dhrubajyoti_Kurmi', 'indices': [...</td>\n",
       "      <td>[{'screen_name': 'MoHFW_INDIA', 'name': 'Minis...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>lazizpizza99</td>\n",
       "      <td>Jasola Vihar, New Delhi</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-08 21:28:48+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>sleeping suddenly bed start shaking ignored ke...</td>\n",
       "      <td>[{'text': 'peace', 'indices': [231, 237]}, {'t...</td>\n",
       "      <td>[{'screen_name': 'LtGovDelhi', 'name': 'LG Del...</td>\n",
       "      <td>0.198333</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>UtkarshMishra_9</td>\n",
       "      <td>Noida, India</td>\n",
       "      <td>707</td>\n",
       "      <td>1122</td>\n",
       "      <td>2022-11-08 21:14:55+00:00</td>\n",
       "      <td>5764</td>\n",
       "      <td>0</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>[{'text': 'earthquake', 'indices': [137, 148]}...</td>\n",
       "      <td>[{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user_id  tweet_id         username                 location  \\\n",
       "0           0        2         2       pspatilsbi               Bangalore    \n",
       "1           1        3         3         ththegde   Kandivali East, Mumbai   \n",
       "2           2        5         5      rupz_boruah            Chabua, India   \n",
       "3           3        8         8     lazizpizza99  Jasola Vihar, New Delhi   \n",
       "4           4       11        11  UtkarshMishra_9             Noida, India   \n",
       "\n",
       "   following  followers             twt_created_at  total_tweets  \\\n",
       "0        325         25  2022-11-08 22:08:44+00:00          2704   \n",
       "1        582         57  2022-11-08 22:00:49+00:00          1969   \n",
       "2         14         33  2022-11-08 21:54:37+00:00           309   \n",
       "3         23          1  2022-11-08 21:28:48+00:00             6   \n",
       "4        707       1122  2022-11-08 21:14:55+00:00          5764   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                     agenda great old god blees end   \n",
       "1              0  please allow citizen buy forex investment like...   \n",
       "2              0  please take necessary action neurologist amc d...   \n",
       "3              0  sleeping suddenly bed start shaking ignored ke...   \n",
       "4              0  estimated magnitude earthquake affected countr...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'text': 'Dr_Dhrubajyoti_Kurmi', 'indices': [...   \n",
       "3  [{'text': 'peace', 'indices': [231, 237]}, {'t...   \n",
       "4  [{'text': 'earthquake', 'indices': [137, 148]}...   \n",
       "\n",
       "                                            mentions  textblob_polarity  \\\n",
       "0  [{'screen_name': 'INCIndia', 'name': 'Congress...           0.450000   \n",
       "1  [{'screen_name': 'PMOIndia', 'name': 'PMO Indi...           0.000000   \n",
       "2  [{'screen_name': 'MoHFW_INDIA', 'name': 'Minis...           0.033333   \n",
       "3  [{'screen_name': 'LtGovDelhi', 'name': 'LG Del...           0.198333   \n",
       "4  [{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...           0.000000   \n",
       "\n",
       "   nltk_compound  avg_sentiment  textblob_sentiment  nltk_sentiment  \n",
       "0         0.7351              1                   1               1  \n",
       "1         0.8020              1                   0               1  \n",
       "2         0.6369              1                   1               1  \n",
       "3         0.6597              1                   1               1  \n",
       "4        -0.1531             -1                   0              -1  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping user_id, username, location, following, followers, twt_created_at, total_tweets, retweet_count, hashtags, mentions, tweet_id_dup\n",
    "tweets_df.drop(['Unnamed: 0', 'user_id', 'tweet_id', 'username', 'location', 'following', 'followers', 'twt_created_at', 'total_tweets', 'retweet_count', 'hashtags', 'mentions', 'textblob_polarity', 'nltk_compound', 'textblob_sentiment', 'nltk_sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'avg_sentiment'], dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>avg_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agenda great old god blees end</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please allow citizen buy forex investment like...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please take necessary action neurologist amc d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sleeping suddenly bed start shaking ignored ke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  avg_sentiment\n",
       "0                     agenda great old god blees end              1\n",
       "1  please allow citizen buy forex investment like...              1\n",
       "2  please take necessary action neurologist amc d...              1\n",
       "3  sleeping suddenly bed start shaking ignored ke...              1\n",
       "4  estimated magnitude earthquake affected countr...             -1"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    418\n",
       "-1    195\n",
       " 0     38\n",
       "Name: avg_sentiment, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['avg_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_tokens(df):\n",
    "    tokens = list()\n",
    "    tokenizer = TweetTokenizer()\n",
    "    \n",
    "    for tweets in df.loc[:, 'text']:\n",
    "        # print(len(tokenizer.tokenize(tweets)))\n",
    "        tokens.append(tokenizer.tokenize(tweets))\n",
    "    \n",
    "    df['tokens'] = tokens\n",
    "    \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    # Get the stemmed_tokens\n",
    "    df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df['tokens']]\n",
    "    df['stemmed_tokens'].head(10)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agenda great old god blees end</td>\n",
       "      <td>1</td>\n",
       "      <td>[agenda, great, old, god, blees, end]</td>\n",
       "      <td>[agenda, great, old, god, blee, end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please allow citizen buy forex investment like...</td>\n",
       "      <td>1</td>\n",
       "      <td>[please, allow, citizen, buy, forex, investmen...</td>\n",
       "      <td>[pleas, allow, citizen, bui, forex, invest, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please take necessary action neurologist amc d...</td>\n",
       "      <td>1</td>\n",
       "      <td>[please, take, necessary, action, neurologist,...</td>\n",
       "      <td>[pleas, take, necessari, action, neurologist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sleeping suddenly bed start shaking ignored ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>[sleeping, suddenly, bed, start, shaking, igno...</td>\n",
       "      <td>[sleep, suddenli, bed, start, shake, ignor, ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[estimated, magnitude, earthquake, affected, c...</td>\n",
       "      <td>[estim, magnitud, earthquak, affect, countri, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  avg_sentiment  \\\n",
       "0                     agenda great old god blees end              1   \n",
       "1  please allow citizen buy forex investment like...              1   \n",
       "2  please take necessary action neurologist amc d...              1   \n",
       "3  sleeping suddenly bed start shaking ignored ke...              1   \n",
       "4  estimated magnitude earthquake affected countr...             -1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0              [agenda, great, old, god, blees, end]   \n",
       "1  [please, allow, citizen, buy, forex, investmen...   \n",
       "2  [please, take, necessary, action, neurologist,...   \n",
       "3  [sleeping, suddenly, bed, start, shaking, igno...   \n",
       "4  [estimated, magnitude, earthquake, affected, c...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0               [agenda, great, old, god, blee, end]  \n",
       "1  [pleas, allow, citizen, bui, forex, invest, li...  \n",
       "2  [pleas, take, necessari, action, neurologist, ...  \n",
       "3  [sleep, suddenli, bed, start, shake, ignor, ke...  \n",
       "4  [estim, magnitud, earthquak, affect, countri, ...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = creating_tokens(tweets_df)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df['stemmed_tokens'], df['avg_sentiment'], test_size=test_size, random_state=42, stratify=df['avg_sentiment'])\n",
    "    \n",
    "    print(y_train.value_counts())\n",
    "    print(y_test.value_counts())\n",
    "    # print(type(x_train))\n",
    "    # print(type(y_train))\n",
    "    \n",
    "    x_train = x_train.to_frame()\n",
    "    x_train = x_train.reset_index()\n",
    "    \n",
    "    x_test = x_test.to_frame()\n",
    "    x_test = x_test.reset_index()\n",
    "    \n",
    "    y_train = y_train.to_frame()\n",
    "    y_train = y_train.reset_index()\n",
    "    \n",
    "    y_test = y_test.to_frame()\n",
    "    y_test = y_test.reset_index()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    292\n",
      "-1    136\n",
      " 0     27\n",
      "Name: avg_sentiment, dtype: int64\n",
      " 1    126\n",
      "-1     59\n",
      " 0     11\n",
      "Name: avg_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(tweets_df, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                     stemmed_tokens\n",
      "0    106  [narendra, modi, launch, logo, said, logo, mes...\n",
      "1     64  [could, prevent, mani, scam, dynast, massiv, d...\n",
      "2     32  [journei, toward, chang, initi, good, report, ...\n",
      "3    118  [democraci, india, evm, tamper, medium, becam,...\n",
      "4    167  [free, medic, camp, organis, jan, aushadhi, op...\n",
      "   index                                     stemmed_tokens\n",
      "0    548  [gujarat, give, love, sweet, nashta, food, cha...\n",
      "1    532  [rememb, great, person, let, gener, judg, extr...\n",
      "2    209  [vasudaiva, kutumbakam, signatur, india, compa...\n",
      "3     28  [claim, submit, onlin, portal, yahi, statu, sh...\n",
      "4    173  [delhi, terribl, vouch, hvng, experienc, last,...\n",
      "   index  avg_sentiment\n",
      "0    106              1\n",
      "1     64              1\n",
      "2     32              1\n",
      "3    118              0\n",
      "4    167              1\n",
      "   index  avg_sentiment\n",
      "0    548              1\n",
      "1    532              1\n",
      "2    209              1\n",
      "3     28              0\n",
      "4    173             -1\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "print(x_test.head())\n",
    "print(y_train.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = -1\n",
    "for tweets in tweets_df.loc[:, 'stemmed_tokens']:\n",
    "    if(max_len < len(tweets)):\n",
    "        max_len = len(tweets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 1.063798189163208\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "OUTPUT_FOLDER = '/Users/nitanshjain/Documents/Thapar 4th Sem/Machine Learing/Machine_Learning_Project/'\n",
    "\n",
    "start_time = time.time()\n",
    "tokens = pd.Series(tweets_df['stemmed_tokens']).values\n",
    "# print(tokens)\n",
    "word2vec_model_file = OUTPUT_FOLDER + 'word2vec_' + str(200) + '.model'\n",
    "\n",
    "w2v_model = Word2Vec(tokens, min_count=1, vector_size=200, window=5, workers=4, sg=2)\n",
    "w2v_model.train(tokens, epochs=10, total_examples=len(tokens))\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\n",
    "w2v_model.save(word2vec_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(create_file, model_file, x):\n",
    "    sg_w2v_model = Word2Vec.load(model_file)\n",
    "    \n",
    "    with open(create_file, 'w+') as word2vec_file:\n",
    "        for index, row in x.iterrows():\n",
    "            model_vector = (np.mean([sg_w2v_model.wv[token] for token in row['stemmed_tokens']], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(200))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            \n",
    "            if type(model_vector) is list:\n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(200)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "    \n",
    "    df = pd.read_csv(create_file)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.018076</td>\n",
       "      <td>0.011372</td>\n",
       "      <td>0.038198</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>0.056289</td>\n",
       "      <td>-0.104743</td>\n",
       "      <td>-0.077448</td>\n",
       "      <td>0.227835</td>\n",
       "      <td>-0.069157</td>\n",
       "      <td>0.112864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144789</td>\n",
       "      <td>-0.136987</td>\n",
       "      <td>-0.011252</td>\n",
       "      <td>-0.106480</td>\n",
       "      <td>0.085528</td>\n",
       "      <td>0.035771</td>\n",
       "      <td>0.096498</td>\n",
       "      <td>-0.182156</td>\n",
       "      <td>-0.091490</td>\n",
       "      <td>-0.025682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.009849</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>0.041070</td>\n",
       "      <td>0.041798</td>\n",
       "      <td>-0.079154</td>\n",
       "      <td>-0.032831</td>\n",
       "      <td>0.209595</td>\n",
       "      <td>-0.040423</td>\n",
       "      <td>0.094141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122804</td>\n",
       "      <td>-0.112102</td>\n",
       "      <td>-0.048178</td>\n",
       "      <td>-0.096391</td>\n",
       "      <td>0.092991</td>\n",
       "      <td>0.047010</td>\n",
       "      <td>0.075095</td>\n",
       "      <td>-0.136985</td>\n",
       "      <td>-0.066338</td>\n",
       "      <td>-0.012703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019496</td>\n",
       "      <td>0.008106</td>\n",
       "      <td>0.032317</td>\n",
       "      <td>0.053849</td>\n",
       "      <td>0.062072</td>\n",
       "      <td>-0.079141</td>\n",
       "      <td>-0.055643</td>\n",
       "      <td>0.210309</td>\n",
       "      <td>-0.053082</td>\n",
       "      <td>0.107435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142372</td>\n",
       "      <td>-0.122349</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>-0.082683</td>\n",
       "      <td>0.081486</td>\n",
       "      <td>0.056014</td>\n",
       "      <td>0.084179</td>\n",
       "      <td>-0.143580</td>\n",
       "      <td>-0.086266</td>\n",
       "      <td>-0.016943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010925</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.034394</td>\n",
       "      <td>0.052326</td>\n",
       "      <td>0.050722</td>\n",
       "      <td>-0.078212</td>\n",
       "      <td>-0.054323</td>\n",
       "      <td>0.195932</td>\n",
       "      <td>-0.053481</td>\n",
       "      <td>0.097929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130955</td>\n",
       "      <td>-0.116084</td>\n",
       "      <td>-0.021956</td>\n",
       "      <td>-0.078397</td>\n",
       "      <td>0.072493</td>\n",
       "      <td>0.049883</td>\n",
       "      <td>0.083022</td>\n",
       "      <td>-0.135542</td>\n",
       "      <td>-0.078814</td>\n",
       "      <td>-0.015669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014852</td>\n",
       "      <td>0.006526</td>\n",
       "      <td>0.029912</td>\n",
       "      <td>0.041831</td>\n",
       "      <td>0.033212</td>\n",
       "      <td>-0.066289</td>\n",
       "      <td>-0.052569</td>\n",
       "      <td>0.176798</td>\n",
       "      <td>-0.036338</td>\n",
       "      <td>0.083058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110183</td>\n",
       "      <td>-0.103352</td>\n",
       "      <td>-0.028663</td>\n",
       "      <td>-0.081328</td>\n",
       "      <td>0.071953</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>0.068604</td>\n",
       "      <td>-0.121026</td>\n",
       "      <td>-0.057256</td>\n",
       "      <td>-0.009746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.018076  0.011372  0.038198  0.057504  0.056289 -0.104743 -0.077448   \n",
       "1  0.029739  0.009849  0.021209  0.041070  0.041798 -0.079154 -0.032831   \n",
       "2  0.019496  0.008106  0.032317  0.053849  0.062072 -0.079141 -0.055643   \n",
       "3  0.010925  0.005897  0.034394  0.052326  0.050722 -0.078212 -0.054323   \n",
       "4  0.014852  0.006526  0.029912  0.041831  0.033212 -0.066289 -0.052569   \n",
       "\n",
       "          7         8         9  ...       190       191       192       193  \\\n",
       "0  0.227835 -0.069157  0.112864  ...  0.144789 -0.136987 -0.011252 -0.106480   \n",
       "1  0.209595 -0.040423  0.094141  ...  0.122804 -0.112102 -0.048178 -0.096391   \n",
       "2  0.210309 -0.053082  0.107435  ...  0.142372 -0.122349 -0.026313 -0.082683   \n",
       "3  0.195932 -0.053481  0.097929  ...  0.130955 -0.116084 -0.021956 -0.078397   \n",
       "4  0.176798 -0.036338  0.083058  ...  0.110183 -0.103352 -0.028663 -0.081328   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.085528  0.035771  0.096498 -0.182156 -0.091490 -0.025682  \n",
       "1  0.092991  0.047010  0.075095 -0.136985 -0.066338 -0.012703  \n",
       "2  0.081486  0.056014  0.084179 -0.143580 -0.086266 -0.016943  \n",
       "3  0.072493  0.049883  0.083022 -0.135542 -0.078814 -0.015669  \n",
       "4  0.071953  0.039065  0.068604 -0.121026 -0.057256 -0.009746  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_train_filename = OUTPUT_FOLDER + 'word2vec_train_' + str(200) + '.csv'\n",
    "word2vec_train_df = create_file(word2vec_train_filename, word2vec_model_file, x_train)\n",
    "print(word2vec_train_df.shape)\n",
    "word2vec_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037974</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>0.045686</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>-0.074759</td>\n",
       "      <td>-0.034472</td>\n",
       "      <td>0.197542</td>\n",
       "      <td>-0.038955</td>\n",
       "      <td>0.091140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110857</td>\n",
       "      <td>-0.112666</td>\n",
       "      <td>-0.037386</td>\n",
       "      <td>-0.073576</td>\n",
       "      <td>0.072823</td>\n",
       "      <td>0.033760</td>\n",
       "      <td>0.069813</td>\n",
       "      <td>-0.129657</td>\n",
       "      <td>-0.069322</td>\n",
       "      <td>-0.022718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.034220</td>\n",
       "      <td>0.050636</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>-0.085057</td>\n",
       "      <td>-0.050388</td>\n",
       "      <td>0.219376</td>\n",
       "      <td>-0.052754</td>\n",
       "      <td>0.107717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137475</td>\n",
       "      <td>-0.128444</td>\n",
       "      <td>-0.034326</td>\n",
       "      <td>-0.092264</td>\n",
       "      <td>0.089104</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>0.087630</td>\n",
       "      <td>-0.149854</td>\n",
       "      <td>-0.086597</td>\n",
       "      <td>-0.017834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.026014</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.038307</td>\n",
       "      <td>0.058227</td>\n",
       "      <td>0.045578</td>\n",
       "      <td>-0.085853</td>\n",
       "      <td>-0.088061</td>\n",
       "      <td>0.195048</td>\n",
       "      <td>-0.070608</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143563</td>\n",
       "      <td>-0.113067</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>-0.087587</td>\n",
       "      <td>0.072766</td>\n",
       "      <td>0.051799</td>\n",
       "      <td>0.086476</td>\n",
       "      <td>-0.159611</td>\n",
       "      <td>-0.097626</td>\n",
       "      <td>-0.011960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046584</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>0.048586</td>\n",
       "      <td>0.074956</td>\n",
       "      <td>-0.083865</td>\n",
       "      <td>-0.021533</td>\n",
       "      <td>0.242438</td>\n",
       "      <td>-0.051148</td>\n",
       "      <td>0.106349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143391</td>\n",
       "      <td>-0.139552</td>\n",
       "      <td>-0.065461</td>\n",
       "      <td>-0.092510</td>\n",
       "      <td>0.112321</td>\n",
       "      <td>0.045782</td>\n",
       "      <td>0.084568</td>\n",
       "      <td>-0.153077</td>\n",
       "      <td>-0.073667</td>\n",
       "      <td>-0.021090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.041721</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>-0.064722</td>\n",
       "      <td>-0.048218</td>\n",
       "      <td>0.173453</td>\n",
       "      <td>-0.033045</td>\n",
       "      <td>0.087069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110211</td>\n",
       "      <td>-0.100096</td>\n",
       "      <td>-0.029775</td>\n",
       "      <td>-0.081044</td>\n",
       "      <td>0.071949</td>\n",
       "      <td>0.042363</td>\n",
       "      <td>0.069896</td>\n",
       "      <td>-0.121527</td>\n",
       "      <td>-0.058047</td>\n",
       "      <td>-0.014548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.037974  0.003105  0.013955  0.045686  0.067164 -0.074759 -0.034472   \n",
       "1  0.021099  0.009306  0.034220  0.050636  0.060210 -0.085057 -0.050388   \n",
       "2 -0.026014  0.002494  0.038307  0.058227  0.045578 -0.085853 -0.088061   \n",
       "3  0.046584  0.013310  0.019839  0.048586  0.074956 -0.083865 -0.021533   \n",
       "4  0.011807  0.003984  0.027028  0.041721  0.037679 -0.064722 -0.048218   \n",
       "\n",
       "          7         8         9  ...       190       191       192       193  \\\n",
       "0  0.197542 -0.038955  0.091140  ...  0.110857 -0.112666 -0.037386 -0.073576   \n",
       "1  0.219376 -0.052754  0.107717  ...  0.137475 -0.128444 -0.034326 -0.092264   \n",
       "2  0.195048 -0.070608  0.100574  ...  0.143563 -0.113067  0.007735 -0.087587   \n",
       "3  0.242438 -0.051148  0.106349  ...  0.143391 -0.139552 -0.065461 -0.092510   \n",
       "4  0.173453 -0.033045  0.087069  ...  0.110211 -0.100096 -0.029775 -0.081044   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.072823  0.033760  0.069813 -0.129657 -0.069322 -0.022718  \n",
       "1  0.089104  0.050955  0.087630 -0.149854 -0.086597 -0.017834  \n",
       "2  0.072766  0.051799  0.086476 -0.159611 -0.097626 -0.011960  \n",
       "3  0.112321  0.045782  0.084568 -0.153077 -0.073667 -0.021090  \n",
       "4  0.071949  0.042363  0.069896 -0.121527 -0.058047 -0.014548  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_test_filename = OUTPUT_FOLDER + 'word2vec_test_' + str(200) + '.csv'\n",
    "word2vec_test_df = create_file(word2vec_test_filename, word2vec_model_file, x_test)\n",
    "print(word2vec_test_df.shape)\n",
    "word2vec_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 0.07840299606323242\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_decision_word2vec = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model\n",
    "clf_decision_word2vec.fit(word2vec_train_df, y_train['avg_sentiment'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.41      0.44      0.43        59\n",
      "           0       0.06      0.09      0.07        11\n",
      "           1       0.72      0.66      0.69       126\n",
      "\n",
      "    accuracy                           0.56       196\n",
      "   macro avg       0.40      0.40      0.39       196\n",
      "weighted avg       0.59      0.56      0.57       196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "        \n",
    "y_pred_word2vec = clf_decision_word2vec.predict(word2vec_test_df)\n",
    "print(classification_report(y_test['avg_sentiment'], y_pred_word2vec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
