{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:56:01,598 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim.vectors.npy not found in cache, downloading to /var/folders/1y/mk1sttkj7yddgbjksb454nt00000gn/T/tmpj14l4x5i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153M/153M [06:24<00:00, 416kB/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-16 01:02:27,453 copying /var/folders/1y/mk1sttkj7yddgbjksb454nt00000gn/T/tmpj14l4x5i to cache at /Users/arjunkhanchandani/.flair/embeddings/glove.gensim.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-16 01:02:28,499 removing temp file /var/folders/1y/mk1sttkj7yddgbjksb454nt00000gn/T/tmpj14l4x5i\n",
      "2023-08-16 01:02:30,055 https://flair.informatik.hu-berlin.de/resources/embeddings/token/glove.gensim not found in cache, downloading to /var/folders/1y/mk1sttkj7yddgbjksb454nt00000gn/T/tmp7rds8p73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20.5M/20.5M [00:49<00:00, 431kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-16 01:03:21,286 copying /var/folders/1y/mk1sttkj7yddgbjksb454nt00000gn/T/tmp7rds8p73 to cache at /Users/arjunkhanchandani/.flair/embeddings/glove.gensim\n",
      "2023-08-16 01:03:21,305 removing temp file /var/folders/1y/mk1sttkj7yddgbjksb454nt00000gn/T/tmp7rds8p73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/arjunkhanchandani/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchtext\n",
    "import tqdm\n",
    "import copy\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.nn import Classifier\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings\n",
    "tagger = Classifier.load('sentiment-fast')\n",
    "glove_embeddings = WordEmbeddings('glove')\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "from sklearn.cluster import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics.pairwise import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('/Users/arjunkhanchandani/Desktop/twitter_data_analysis-main/v2/data/tweets_cleaned_v2.csv')\n",
    "num_components = 2\n",
    "print(tweets_df.shape)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_tokens(tweets):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweets)\n",
    "    return tokens\n",
    "\n",
    "tweets_df['tweets_tokens'] = tweets_df.apply(lambda x: creating_tokens(x['tweet']), axis=1)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_sentiment_df = tweets_df.copy()\n",
    "tweets_sentiment_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flair_sentiment(tweets):\n",
    "    sentence = Sentence(tweets)\n",
    "    tagger.predict(sentence)\n",
    "    value = sentence.labels[0].to_dict()['value'] \n",
    "    if value == 'POSITIVE':\n",
    "        result = 1\n",
    "    else:\n",
    "        result = -1\n",
    "    return result\n",
    "\n",
    "tweets_sentiment_df['sentiment_flair'] = tweets_sentiment_df.apply(lambda x: get_flair_sentiment(x['tweet']), axis=1)\n",
    "tweets_sentiment_df.head()\n",
    "\n",
    "# x = get_flair_sentiment('this is not a movie')\n",
    "# x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nltk_sentiment(tweet):\n",
    "    sia  = SentimentIntensityAnalyzer()\n",
    "    compound = sia.polarity_scores(tweet)['compound']\n",
    "    if compound >= 0:\n",
    "        sentiment = 1\n",
    "    else:\n",
    "        sentiment = -1\n",
    "    return sentiment\n",
    "\n",
    "tweets_sentiment_df['sentiment_nltk'] = tweets_sentiment_df.apply(lambda x: get_nltk_sentiment(x['tweet']), axis=1)\n",
    "tweets_sentiment_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf_embeddings = tfidf.fit_transform(tweets_sentiment_df['tweet'])\n",
    "tfidf_embeddings = np.asarray(tfidf_embeddings.todense())\n",
    "tfidf_embeddings = mm.fit_transform(tfidf_embeddings)\n",
    "\n",
    "#PCA\n",
    "tfidf_embeddings_pca = PCA(n_components=num_components).fit_transform(tfidf_embeddings)\n",
    "tfidf_embeddings_pca.shape\n",
    "\n",
    "#NMF\n",
    "nmf = NMF(n_components=num_components)\n",
    "tfidf_embeddings_nmf = nmf.fit_transform(tfidf_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_tfidf = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=tfidf_embeddings_pca)\n",
    "positive_cluster_center = kmeans_tfidf.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_tfidf.cluster_centers_[1]\n",
    "\n",
    "tfidf_labels = kmeans_tfidf.predict(tfidf_embeddings_pca)\n",
    "plt.scatter(tfidf_embeddings_pca[:,0], tfidf_embeddings_pca[:,1], c=kmeans_tfidf.labels_, cmap='viridis', s=5)\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_kmeans_pca'] = tfidf_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_tfidf = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_tfidf.fit(X=tfidf_embeddings_pca)\n",
    "plt.scatter(tfidf_embeddings_pca[:,0], tfidf_embeddings_pca[:,1], c=agg_ward_tfidf.labels_, cmap='viridis', s=5)\n",
    "\n",
    "tfidf_labels = agg_ward_tfidf.labels_\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_agg_ward_pca'] = tfidf_labels\n",
    "\n",
    "#complete\n",
    "agg_complete_tfidf = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_tfidf.fit(X=tfidf_embeddings_pca)\n",
    "plt.scatter(tfidf_embeddings_pca[:,0], tfidf_embeddings_pca[:,1], c=agg_complete_tfidf.labels_, cmap='viridis', s=5)\n",
    "\n",
    "tfidf_labels = agg_complete_tfidf.labels_\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_agg_complete_pca'] = tfidf_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_tfidf = Birch(n_clusters=2, threshold=0.000001, branching_factor=5)\n",
    "birch_tfidf.fit(tfidf_embeddings_pca)\n",
    "plt.scatter(tfidf_embeddings_pca[:,0], tfidf_embeddings_pca[:,1], c=birch_tfidf.labels_, cmap='viridis', s=5)\n",
    "\n",
    "tfidf_labels = birch_tfidf.labels_\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_birch_pca'] = tfidf_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_tfidf = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=tfidf_embeddings_nmf)\n",
    "positive_cluster_center = kmeans_tfidf.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_tfidf.cluster_centers_[1]\n",
    "\n",
    "tfidf_labels = kmeans_tfidf.predict(tfidf_embeddings_nmf)\n",
    "plt.scatter(tfidf_embeddings_nmf[:,0], tfidf_embeddings_nmf[:,1], c=kmeans_tfidf.labels_, cmap='viridis', s=5)\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_kmeans_mnf'] = tfidf_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_tfidf = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_tfidf.fit(X=tfidf_embeddings_nmf)\n",
    "plt.scatter(tfidf_embeddings_nmf[:,0], tfidf_embeddings_nmf[:,1], c=agg_ward_tfidf.labels_, cmap='viridis', s=5)\n",
    "plt.show()\n",
    "tfidf_labels = agg_ward_tfidf.labels_\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_agg_ward_nmf'] = tfidf_labels\n",
    "\n",
    "#complete\n",
    "agg_complete_tfidf = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_tfidf.fit(X=tfidf_embeddings_nmf)\n",
    "plt.scatter(tfidf_embeddings_nmf[:,0], tfidf_embeddings_nmf[:,1], c=agg_complete_tfidf.labels_, cmap='viridis', s=5)\n",
    "plt.show()\n",
    "tfidf_labels = agg_complete_tfidf.labels_\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_agg_complete_nmf'] = tfidf_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_tfidf = Birch(n_clusters=2, threshold=0.00001, branching_factor=50)\n",
    "birch_tfidf.fit(tfidf_embeddings_nmf)\n",
    "plt.scatter(tfidf_embeddings_nmf[:,0], tfidf_embeddings_nmf[:,1], c=birch_tfidf.labels_, cmap='viridis', s=5)\n",
    "\n",
    "tfidf_labels = birch_tfidf.labels_\n",
    "print(Counter(tfidf_labels))\n",
    "print(tfidf_labels)\n",
    "tweets_sentiment_df['sentiment_tfidf_birch_nmf'] = tfidf_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 200\n",
    "window_size = 5\n",
    "min_word = 2\n",
    "down_sampling = 1e-2\n",
    "tokens = tweets_sentiment_df['tweets_tokens']\n",
    "\n",
    "\n",
    "fast_text_model = FastText(\n",
    "                        sample=down_sampling,\n",
    "                        workers = 4,\n",
    "                        sg=1\n",
    "                    )\n",
    "\n",
    "fast_text_model.build_vocab(tokens)\n",
    "fast_text_model.train(tokens, total_examples=fast_text_model.corpus_count, epochs=fast_text_model.epochs)\n",
    "\n",
    "fasttext_embeddings = np.array([np.mean([fast_text_model.wv[word] for word in token], axis=0) for token in tokens])\n",
    "fasttext_embeddings.shape\n",
    "\n",
    "# fasttext_embeddings = np.asarray(fasttext_embeddings.todense())\n",
    "fasttext_embeddings = mm.fit_transform(fasttext_embeddings)\n",
    "\n",
    "#PCA\n",
    "# fasttext_embeddings = np.asarray(fasttext_embeddings)\n",
    "fasttext_embeddings_pca = PCA(n_components=num_components).fit_transform(fasttext_embeddings)\n",
    "print(fasttext_embeddings_pca.shape)\n",
    "\n",
    "# #NMF\n",
    "nmf = NMF(n_components=num_components)\n",
    "fasttext_embeddings_nmf = nmf.fit_transform(fasttext_embeddings)\n",
    "print(fasttext_embeddings_nmf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_fasttext = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=fasttext_embeddings_pca)\n",
    "positive_cluster_center = kmeans_fasttext.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_fasttext.cluster_centers_[1]\n",
    "\n",
    "fasttext_labels = kmeans_fasttext.predict(fasttext_embeddings_pca)\n",
    "plt.scatter(fasttext_embeddings_pca[:,0], fasttext_embeddings_pca[:,1], c=kmeans_fasttext.labels_, cmap='viridis', s=5)\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_kmeans_pca'] = fasttext_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_fasttext = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_fasttext.fit(X=fasttext_embeddings_pca)\n",
    "fasttext_labels = agg_ward_fasttext.labels_\n",
    "plt.scatter(fasttext_embeddings_pca[:,0], fasttext_embeddings_pca[:,1], c=agg_ward_fasttext.labels_, cmap='viridis', s=5)\n",
    "plt.show()\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_agg_ward_pca'] = fasttext_labels\n",
    "\n",
    "# #complete\n",
    "agg_complete_fasttext = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_fasttext.fit(X=fasttext_embeddings_pca)\n",
    "fasttext_labels = agg_complete_fasttext.labels_\n",
    "plt.scatter(fasttext_embeddings_pca[:,0], fasttext_embeddings_pca[:,1], c=agg_complete_fasttext.labels_, cmap='viridis', s=5)\n",
    "plt.show()\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_agg_complete_pca'] = fasttext_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_fasttext = Birch(n_clusters=2, threshold=0.00001, branching_factor=50)\n",
    "birch_fasttext.fit(fasttext_embeddings_pca)\n",
    "plt.scatter(fasttext_embeddings_pca[:,0], fasttext_embeddings_pca[:,1], c=birch_fasttext.labels_, cmap='viridis', s=5)\n",
    "\n",
    "fasttext_labels = birch_fasttext.labels_\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_birch_pca'] = fasttext_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_fasttext = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=fasttext_embeddings_nmf)\n",
    "positive_cluster_center = kmeans_fasttext.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_fasttext.cluster_centers_[1]\n",
    "\n",
    "fasttext_labels = kmeans_fasttext.predict(fasttext_embeddings_nmf)\n",
    "plt.scatter(fasttext_embeddings_nmf[:,0], fasttext_embeddings_nmf[:,1], c=kmeans_fasttext.labels_, cmap='viridis', s=5)\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_kmeans_nmf'] = fasttext_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_fasttext = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_fasttext.fit(X=fasttext_embeddings_nmf)\n",
    "fasttext_labels = agg_ward_fasttext.labels_\n",
    "plt.scatter(fasttext_embeddings_nmf[:,0], fasttext_embeddings_nmf[:,1], c=agg_ward_fasttext.labels_, cmap='viridis', s=5)\n",
    "plt.show()\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_agg_ward_nmf'] = fasttext_labels\n",
    "\n",
    "# #complete\n",
    "agg_complete_fasttext = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_fasttext.fit(X=fasttext_embeddings_nmf)\n",
    "fasttext_labels = agg_complete_fasttext.labels_\n",
    "plt.scatter(fasttext_embeddings_nmf[:,0], fasttext_embeddings_nmf[:,1], c=agg_complete_fasttext.labels_, cmap='viridis', s=5)\n",
    "plt.show()\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_agg_complete_nmf'] = fasttext_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_fasttext = Birch(n_clusters=2, threshold=0.00001, branching_factor=50)\n",
    "birch_fasttext.fit(fasttext_embeddings_nmf)\n",
    "plt.scatter(fasttext_embeddings_nmf[:,0], fasttext_embeddings_nmf[:,1], c=birch_fasttext.labels_, cmap='viridis', s=5)\n",
    "\n",
    "fasttext_labels = birch_fasttext.labels_\n",
    "print(Counter(fasttext_labels))\n",
    "print(fasttext_labels)\n",
    "tweets_sentiment_df['sentiment_fasttext_birch_nmf'] = fasttext_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_tokens = tweets_sentiment_df['tweets_tokens']\n",
    "\n",
    "#Detecting Common Phrases so each word is treated as its own\n",
    "tweets_phrases = gensim.models.phrases.Phrases(tweets_tokens)\n",
    "tweets_phraser = gensim.models.phrases.Phraser(tweets_phrases)\n",
    "tweets_phrase = tweets_phraser[tweets_tokens]\n",
    "\n",
    "MODEL_TRAIN = gensim.models.word2vec.Word2Vec(sentences=tweets_phrase, workers=2)\n",
    "\n",
    "def word2vec(tokens, model, text_input):\n",
    "    embeddings = []\n",
    "    for row in text_input:\n",
    "        row_vector = np.zeros(model.vector_size)\n",
    "        for word in row:\n",
    "            if word in model.wv.index_to_key:\n",
    "                word_vector = model.wv[word]\n",
    "                row_vector += word_vector\n",
    "        embeddings.append(row_vector)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "word2vec_embeddings = word2vec(tweets_phrase, MODEL_TRAIN, tweets_phrase)\n",
    "word2vec_embeddings.shape\n",
    "\n",
    "word2vec_embeddings = mm.fit_transform(word2vec_embeddings)\n",
    "\n",
    "#PCA\n",
    "# word2vec_embeddings = np.asarray(word2vec_embeddings)\n",
    "word2vec_embeddings_pca = PCA(n_components=num_components).fit_transform(word2vec_embeddings)\n",
    "print(word2vec_embeddings_pca.shape)\n",
    "\n",
    "# #NMF\n",
    "nmf = NMF(n_components=num_components)\n",
    "word2vec_embeddings_nmf = nmf.fit_transform(word2vec_embeddings)\n",
    "print(word2vec_embeddings_nmf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_word2vec = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=word2vec_embeddings_pca)\n",
    "positive_cluster_center = kmeans_word2vec.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_word2vec.cluster_centers_[1]\n",
    "\n",
    "word2vec_labels = kmeans_word2vec.predict(word2vec_embeddings_pca)\n",
    "plt.scatter(word2vec_embeddings_pca[:,0], word2vec_embeddings_pca[:,1], c=kmeans_word2vec.labels_, cmap='viridis', s=5)\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_kmeans_pca'] = word2vec_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_word2vec = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_word2vec.fit(X=word2vec_embeddings_pca)\n",
    "word2vec_labels = agg_ward_word2vec.labels_\n",
    "plt.scatter(word2vec_embeddings_pca[:,0], word2vec_embeddings_pca[:,1], c=agg_ward_word2vec.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_agg_ward_pca'] = word2vec_labels\n",
    "\n",
    "#complete\n",
    "agg_complete_word2vec = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_word2vec.fit(X=word2vec_embeddings_pca)\n",
    "word2vec_labels = agg_complete_word2vec.labels_\n",
    "plt.scatter(word2vec_embeddings_pca[:,0], word2vec_embeddings_pca[:,1], c=agg_complete_word2vec.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_agg_complete_pca'] = word2vec_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_word2vec = Birch(n_clusters=2, threshold=0.00001, branching_factor=50)\n",
    "birch_word2vec.fit(word2vec_embeddings_pca)\n",
    "plt.scatter(word2vec_embeddings_pca[:,0], word2vec_embeddings_pca[:,1], c=birch_word2vec.labels_, cmap='viridis', s=5)\n",
    "\n",
    "word2vec_labels = birch_word2vec.labels_\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_birch_pca'] = word2vec_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_word2vec = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=word2vec_embeddings_nmf)\n",
    "positive_cluster_center = kmeans_word2vec.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_word2vec.cluster_centers_[1]\n",
    "\n",
    "word2vec_labels = kmeans_word2vec.predict(word2vec_embeddings_nmf)\n",
    "plt.scatter(word2vec_embeddings_nmf[:,0], word2vec_embeddings_nmf[:,1], c=kmeans_word2vec.labels_, cmap='viridis', s=5)\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_kmeans_nmf'] = word2vec_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_word2vec = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_word2vec.fit(X=word2vec_embeddings_nmf)\n",
    "word2vec_labels = agg_ward_word2vec.labels_\n",
    "plt.scatter(word2vec_embeddings_nmf[:,0], word2vec_embeddings_nmf[:,1], c=agg_ward_word2vec.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_agg_ward_nmf'] = word2vec_labels\n",
    "\n",
    "#complete\n",
    "agg_complete_word2vec = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_word2vec.fit(X=word2vec_embeddings_nmf)\n",
    "word2vec_labels = agg_complete_word2vec.labels_\n",
    "plt.scatter(word2vec_embeddings_nmf[:,0], word2vec_embeddings_nmf[:,1], c=agg_complete_word2vec.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_agg_complete_nmf'] = word2vec_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_word2vec = Birch(n_clusters=2, threshold=0.00001, branching_factor=50)\n",
    "birch_word2vec.fit(word2vec_embeddings_nmf)\n",
    "plt.scatter(word2vec_embeddings_nmf[:,0], word2vec_embeddings_nmf[:,1], c=birch_word2vec.labels_, cmap='viridis', s=5)\n",
    "\n",
    "word2vec_labels = birch_word2vec.labels_\n",
    "print(Counter(word2vec_labels))\n",
    "print(word2vec_labels)\n",
    "tweets_sentiment_df['sentiment_word2vec_birch_nmf'] = word2vec_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = torchtext.vocab.GloVe(name=\"6B\", dim=200, max_vectors=10000)\n",
    "def split_text(text):\n",
    "    return text.split()\n",
    "\n",
    "def get_glove_embeddings(glove_vector, x_train_input):\n",
    "    train = []\n",
    "    for line in enumerate(x_train_input):\n",
    "        text = line[-1]\n",
    "        vector_sum = sum(glove_vector[w] for w in split_text(text))\n",
    "        label = torch.tensor(int(line[0] == \"4\")).long()\n",
    "        train.append((vector_sum, label))\n",
    "            \n",
    "    return train\n",
    "\n",
    "glove_embeddings = get_glove_embeddings(glove, tweets_sentiment_df['tweet'])\n",
    "glove_embeddings = np.array([x[0].numpy() for x in glove_embeddings])\n",
    "\n",
    "glove_embeddings = mm.fit_transform(glove_embeddings)\n",
    "\n",
    "#PCA\n",
    "glove_embeddings_pca = PCA(n_components=num_components).fit_transform(glove_embeddings)\n",
    "print(glove_embeddings_pca.shape)\n",
    "\n",
    "# #NMF\n",
    "nmf = NMF(n_components=num_components)\n",
    "glove_embeddings_nmf = nmf.fit_transform(glove_embeddings)\n",
    "print(glove_embeddings_nmf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_glove = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=glove_embeddings_pca)\n",
    "positive_cluster_center = kmeans_glove.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_glove.cluster_centers_[1]\n",
    "\n",
    "glove_labels = kmeans_glove.predict(glove_embeddings_pca)\n",
    "plt.scatter(glove_embeddings_pca[:,0], glove_embeddings_pca[:,1], c=kmeans_glove.labels_, cmap='viridis', s=5)\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_kmeans_pca'] = glove_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_glove = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_glove.fit(X=glove_embeddings_pca)\n",
    "glove_labels = agg_ward_glove.labels_\n",
    "plt.scatter(glove_embeddings_pca[:,0], glove_embeddings_pca[:,1], c=agg_ward_glove.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_agg_ward_pca'] = glove_labels\n",
    "\n",
    "#complete\n",
    "agg_complete_glove = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_glove.fit(X=glove_embeddings_pca)\n",
    "glove_labels = agg_complete_glove.labels_\n",
    "plt.scatter(glove_embeddings_pca[:,0], glove_embeddings_pca[:,1], c=agg_complete_glove.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_agg_complete_pca'] = glove_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_glove = Birch(n_clusters=2, threshold=0.00001, branching_factor=50)\n",
    "birch_glove.fit(glove_embeddings_pca)\n",
    "plt.scatter(glove_embeddings_pca[:,0], glove_embeddings_pca[:,1], c=birch_glove.labels_, cmap='viridis', s=5)\n",
    "\n",
    "glove_labels = birch_glove.labels_\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_birch_pca'] = glove_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_glove = KMeans(n_clusters=2, max_iter=100, random_state=42).fit(X=glove_embeddings_nmf)\n",
    "positive_cluster_center = kmeans_glove.cluster_centers_[0]\n",
    "negative_cluster_center = kmeans_glove.cluster_centers_[1]\n",
    "\n",
    "glove_labels = kmeans_glove.predict(glove_embeddings_nmf)\n",
    "plt.scatter(glove_embeddings_nmf[:,0], glove_embeddings_nmf[:,1], c=kmeans_glove.labels_, cmap='viridis', s=5)\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_kmeans_nmf'] = glove_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ward \n",
    "agg_ward_glove = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
    "agg_ward_glove.fit(X=glove_embeddings_nmf)\n",
    "glove_labels = agg_ward_glove.labels_\n",
    "plt.scatter(glove_embeddings_nmf[:,0], glove_embeddings_nmf[:,1], c=agg_ward_glove.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_agg_ward_nmf'] = glove_labels\n",
    "\n",
    "#complete\n",
    "agg_complete_glove = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='complete')\n",
    "agg_complete_glove.fit(X=glove_embeddings_nmf)\n",
    "glove_labels = agg_complete_glove.labels_\n",
    "plt.scatter(glove_embeddings_nmf[:,0], glove_embeddings_nmf[:,1], c=agg_complete_glove.labels_, cmap='viridis', s=1)\n",
    "plt.show()\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_agg_complete_nmf'] = glove_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Birch Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch_glove = Birch(n_clusters=2, threshold=0.00001, branching_factor=50)\n",
    "birch_glove.fit(glove_embeddings_nmf)\n",
    "plt.scatter(glove_embeddings_nmf[:,0], glove_embeddings_nmf[:,1], c=birch_glove.labels_, cmap='viridis', s=5)\n",
    "\n",
    "glove_labels = birch_glove.labels_\n",
    "print(Counter(glove_labels))\n",
    "print(glove_labels)\n",
    "tweets_sentiment_df['sentiment_glove_birch_nmf'] = glove_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_sentiment_df.sentiment_flair.value_counts())\n",
    "print(tweets_sentiment_df.sentiment_nltk.value_counts())\n",
    "print(tweets_sentiment_df.sentiment_flair_glove_embed_kmeans.value_counts())\n",
    "# print(tweets_sentiment_df.sentiment_flair_document_embed_kmeans.value_counts())\n",
    "print(tweets_sentiment_df.sentiment_fast_text_embed_kmeans.value_counts())\n",
    "print(tweets_sentiment_df.sentiment_fast_text_embed_nmf_kmeans.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(tweets_sentiment_df, '/Users/arjunkhanchandani/Desktop/twitter_data_analysis-main/v2/data/tweets_with_sentiment__version_2_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pub.towardsai.net/sentiment-analysis-without-modeling-textblob-vs-vader-vs-flair-657b7af855f4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Twitter_Data_Analysis-wZ120kVj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
