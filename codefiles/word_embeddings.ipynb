{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning specialisation coursera \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605, 18)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('data/sentiment.csv')\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>twt_created_at</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>nltk_compound</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>nltk_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>pspatilsbi</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>325</td>\n",
       "      <td>25</td>\n",
       "      <td>2022-11-08 22:08:44+00:00</td>\n",
       "      <td>2704</td>\n",
       "      <td>0</td>\n",
       "      <td>agenda great old god blees end</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'INCIndia', 'name': 'Congress...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ththegde</td>\n",
       "      <td>Kandivali East, Mumbai</td>\n",
       "      <td>582</td>\n",
       "      <td>57</td>\n",
       "      <td>2022-11-08 22:00:49+00:00</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>please allow citizen buy forex investment like...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'PMOIndia', 'name': 'PMO Indi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>rupz_boruah</td>\n",
       "      <td>Chabua, India</td>\n",
       "      <td>14</td>\n",
       "      <td>33</td>\n",
       "      <td>2022-11-08 21:54:37+00:00</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>please take necessary action neurologist amc d...</td>\n",
       "      <td>[{'text': 'Dr_Dhrubajyoti_Kurmi', 'indices': [...</td>\n",
       "      <td>[{'screen_name': 'MoHFW_INDIA', 'name': 'Minis...</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>lazizpizza99</td>\n",
       "      <td>Jasola Vihar, New Delhi</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-08 21:28:48+00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>sleeping suddenly bed start shaking ignored ke...</td>\n",
       "      <td>[{'text': 'peace', 'indices': [231, 237]}, {'t...</td>\n",
       "      <td>[{'screen_name': 'LtGovDelhi', 'name': 'LG Del...</td>\n",
       "      <td>0.198333</td>\n",
       "      <td>0.6597</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>UtkarshMishra_9</td>\n",
       "      <td>Noida, India</td>\n",
       "      <td>707</td>\n",
       "      <td>1122</td>\n",
       "      <td>2022-11-08 21:14:55+00:00</td>\n",
       "      <td>5764</td>\n",
       "      <td>0</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>[{'text': 'earthquake', 'indices': [137, 148]}...</td>\n",
       "      <td>[{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user_id  tweet_id         username                 location  \\\n",
       "0           0        2         2       pspatilsbi               Bangalore    \n",
       "1           1        3         3         ththegde   Kandivali East, Mumbai   \n",
       "2           2        5         5      rupz_boruah            Chabua, India   \n",
       "3           3        8         8     lazizpizza99  Jasola Vihar, New Delhi   \n",
       "4           4       11        11  UtkarshMishra_9             Noida, India   \n",
       "\n",
       "   following  followers             twt_created_at  total_tweets  \\\n",
       "0        325         25  2022-11-08 22:08:44+00:00          2704   \n",
       "1        582         57  2022-11-08 22:00:49+00:00          1969   \n",
       "2         14         33  2022-11-08 21:54:37+00:00           309   \n",
       "3         23          1  2022-11-08 21:28:48+00:00             6   \n",
       "4        707       1122  2022-11-08 21:14:55+00:00          5764   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0                     agenda great old god blees end   \n",
       "1              0  please allow citizen buy forex investment like...   \n",
       "2              0  please take necessary action neurologist amc d...   \n",
       "3              0  sleeping suddenly bed start shaking ignored ke...   \n",
       "4              0  estimated magnitude earthquake affected countr...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'text': 'Dr_Dhrubajyoti_Kurmi', 'indices': [...   \n",
       "3  [{'text': 'peace', 'indices': [231, 237]}, {'t...   \n",
       "4  [{'text': 'earthquake', 'indices': [137, 148]}...   \n",
       "\n",
       "                                            mentions  textblob_polarity  \\\n",
       "0  [{'screen_name': 'INCIndia', 'name': 'Congress...           0.450000   \n",
       "1  [{'screen_name': 'PMOIndia', 'name': 'PMO Indi...           0.000000   \n",
       "2  [{'screen_name': 'MoHFW_INDIA', 'name': 'Minis...           0.033333   \n",
       "3  [{'screen_name': 'LtGovDelhi', 'name': 'LG Del...           0.198333   \n",
       "4  [{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...           0.000000   \n",
       "\n",
       "   nltk_compound  avg_sentiment  textblob_sentiment  nltk_sentiment  \n",
       "0         0.7351              1                   1               1  \n",
       "1         0.8020              1                   0               1  \n",
       "2         0.6369              1                   1               1  \n",
       "3         0.6597              1                   1               1  \n",
       "4        -0.1531             -1                   0              -1  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping user_id, username, location, following, followers, twt_created_at, total_tweets, retweet_count, hashtags, mentions, tweet_id_dup\n",
    "tweets_df.drop(['Unnamed: 0', 'user_id', 'tweet_id', 'username', 'location', 'following', 'followers', 'twt_created_at', 'total_tweets', 'retweet_count', 'hashtags', 'mentions', 'textblob_polarity', 'nltk_compound', 'textblob_sentiment', 'nltk_sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'avg_sentiment'], dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>avg_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agenda great old god blees end</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please allow citizen buy forex investment like...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please take necessary action neurologist amc d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sleeping suddenly bed start shaking ignored ke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  avg_sentiment\n",
       "0                     agenda great old god blees end              1\n",
       "1  please allow citizen buy forex investment like...              1\n",
       "2  please take necessary action neurologist amc d...              1\n",
       "3  sleeping suddenly bed start shaking ignored ke...              1\n",
       "4  estimated magnitude earthquake affected countr...             -1"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    380\n",
       "-1    187\n",
       " 0     38\n",
       "Name: avg_sentiment, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['avg_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_tokens(df):\n",
    "    tokens = list()\n",
    "    tokenizer = TweetTokenizer()\n",
    "    \n",
    "    for tweets in df.loc[:, 'text']:\n",
    "        # print(len(tokenizer.tokenize(tweets)))\n",
    "        tokens.append(tokenizer.tokenize(tweets))\n",
    "    \n",
    "    df['tokens'] = tokens\n",
    "    \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    # Get the stemmed_tokens\n",
    "    df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df['tokens']]\n",
    "    df['stemmed_tokens'].head(10)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agenda great old god blees end</td>\n",
       "      <td>1</td>\n",
       "      <td>[agenda, great, old, god, blees, end]</td>\n",
       "      <td>[agenda, great, old, god, blee, end]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please allow citizen buy forex investment like...</td>\n",
       "      <td>1</td>\n",
       "      <td>[please, allow, citizen, buy, forex, investmen...</td>\n",
       "      <td>[pleas, allow, citizen, bui, forex, invest, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please take necessary action neurologist amc d...</td>\n",
       "      <td>1</td>\n",
       "      <td>[please, take, necessary, action, neurologist,...</td>\n",
       "      <td>[pleas, take, necessari, action, neurologist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sleeping suddenly bed start shaking ignored ke...</td>\n",
       "      <td>1</td>\n",
       "      <td>[sleeping, suddenly, bed, start, shaking, igno...</td>\n",
       "      <td>[sleep, suddenli, bed, start, shake, ignor, ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>-1</td>\n",
       "      <td>[estimated, magnitude, earthquake, affected, c...</td>\n",
       "      <td>[estim, magnitud, earthquak, affect, countri, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  avg_sentiment  \\\n",
       "0                     agenda great old god blees end              1   \n",
       "1  please allow citizen buy forex investment like...              1   \n",
       "2  please take necessary action neurologist amc d...              1   \n",
       "3  sleeping suddenly bed start shaking ignored ke...              1   \n",
       "4  estimated magnitude earthquake affected countr...             -1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0              [agenda, great, old, god, blees, end]   \n",
       "1  [please, allow, citizen, buy, forex, investmen...   \n",
       "2  [please, take, necessary, action, neurologist,...   \n",
       "3  [sleeping, suddenly, bed, start, shaking, igno...   \n",
       "4  [estimated, magnitude, earthquake, affected, c...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0               [agenda, great, old, god, blee, end]  \n",
       "1  [pleas, allow, citizen, bui, forex, invest, li...  \n",
       "2  [pleas, take, necessari, action, neurologist, ...  \n",
       "3  [sleep, suddenli, bed, start, shake, ignor, ke...  \n",
       "4  [estim, magnitud, earthquak, affect, countri, ...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = creating_tokens(tweets_df)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df['stemmed_tokens'], df['avg_sentiment'], test_size=test_size, random_state=42, stratify=df['avg_sentiment'])\n",
    "    \n",
    "    print(y_train.value_counts())\n",
    "    print(y_test.value_counts())\n",
    "    # print(type(x_train))\n",
    "    # print(type(y_train))\n",
    "    \n",
    "    x_train = x_train.to_frame()\n",
    "    x_train = x_train.reset_index()\n",
    "    \n",
    "    x_test = x_test.to_frame()\n",
    "    x_test = x_test.reset_index()\n",
    "    \n",
    "    y_train = y_train.to_frame()\n",
    "    y_train = y_train.reset_index()\n",
    "    \n",
    "    y_test = y_test.to_frame()\n",
    "    y_test = y_test.reset_index()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    266\n",
      "-1    131\n",
      " 0     26\n",
      "Name: avg_sentiment, dtype: int64\n",
      " 1    114\n",
      "-1     56\n",
      " 0     12\n",
      "Name: avg_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(tweets_df, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                     stemmed_tokens\n",
      "0    564  [street, light, road, name, veer, banda, vaira...\n",
      "1    441  [deserv, true, employe, award, honest, whichev...\n",
      "2    447  [gujarat, stone, pelt, vand, bharat, express, ...\n",
      "3    581  [street, light, instal, wall, street, pole, in...\n",
      "4    551  [kab, theek, hoga, yeh, citizen, share, mcd, c...\n",
      "   index                                     stemmed_tokens\n",
      "0     90  [know, hindu, chang, reach, top, posit, know, ...\n",
      "1    602  [open, fire, garbag, park, wast, caus, pollut,...\n",
      "2     45  [proof, heart, honour, prime, minist, shri, na...\n",
      "3     29  [theme, promot, adolesc, friendli, health, car...\n",
      "4    117  [democraci, india, evm, tamper, medium, becam,...\n",
      "   index  avg_sentiment\n",
      "0    564              1\n",
      "1    441              1\n",
      "2    447             -1\n",
      "3    581              1\n",
      "4    551             -1\n",
      "   index  avg_sentiment\n",
      "0     90              1\n",
      "1    602             -1\n",
      "2     45              1\n",
      "3     29              1\n",
      "4    117              0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "print(x_test.head())\n",
    "print(y_train.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = -1\n",
    "for tweets in tweets_df.loc[:, 'stemmed_tokens']:\n",
    "    if(max_len < len(tweets)):\n",
    "        max_len = len(tweets)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 1.1380188465118408\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "OUTPUT_FOLDER = '/Users/nitanshjain/Documents/Thapar 4th Sem/Machine Learing/Machine_Learning_Project/'\n",
    "\n",
    "start_time = time.time()\n",
    "tokens = pd.Series(tweets_df['stemmed_tokens']).values\n",
    "# print(tokens)\n",
    "word2vec_model_file = OUTPUT_FOLDER + 'word2vec_' + str(200) + '.model'\n",
    "\n",
    "w2v_model = Word2Vec(tokens, min_count=1, vector_size=200, window=5, workers=4, sg=2)\n",
    "w2v_model.train(tokens, epochs=10, total_examples=len(tokens))\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\n",
    "w2v_model.save(word2vec_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(create_file, model_file, x):\n",
    "    sg_w2v_model = Word2Vec.load(model_file)\n",
    "    \n",
    "    with open(create_file, 'w+') as word2vec_file:\n",
    "        for index, row in x.iterrows():\n",
    "            model_vector = (np.mean([sg_w2v_model.wv[token] for token in row['stemmed_tokens']], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(200))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            \n",
    "            if type(model_vector) is list:\n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(200)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "    \n",
    "    df = pd.read_csv(create_file)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020882</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>0.074476</td>\n",
       "      <td>0.049863</td>\n",
       "      <td>0.122592</td>\n",
       "      <td>-0.127202</td>\n",
       "      <td>-0.025988</td>\n",
       "      <td>0.255989</td>\n",
       "      <td>-0.063943</td>\n",
       "      <td>0.106702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094013</td>\n",
       "      <td>-0.115644</td>\n",
       "      <td>0.007459</td>\n",
       "      <td>-0.069337</td>\n",
       "      <td>0.146214</td>\n",
       "      <td>0.070044</td>\n",
       "      <td>0.053953</td>\n",
       "      <td>-0.078277</td>\n",
       "      <td>-0.090076</td>\n",
       "      <td>-0.027871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030421</td>\n",
       "      <td>0.011001</td>\n",
       "      <td>0.073398</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.128152</td>\n",
       "      <td>-0.121796</td>\n",
       "      <td>-0.026794</td>\n",
       "      <td>0.244542</td>\n",
       "      <td>-0.053698</td>\n",
       "      <td>0.107955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089291</td>\n",
       "      <td>-0.101986</td>\n",
       "      <td>-0.007420</td>\n",
       "      <td>-0.068880</td>\n",
       "      <td>0.131901</td>\n",
       "      <td>0.070164</td>\n",
       "      <td>0.055305</td>\n",
       "      <td>-0.077764</td>\n",
       "      <td>-0.083086</td>\n",
       "      <td>-0.025791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026502</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.064975</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.108406</td>\n",
       "      <td>-0.111629</td>\n",
       "      <td>-0.027741</td>\n",
       "      <td>0.211317</td>\n",
       "      <td>-0.047374</td>\n",
       "      <td>0.098843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076891</td>\n",
       "      <td>-0.087726</td>\n",
       "      <td>-0.007771</td>\n",
       "      <td>-0.060584</td>\n",
       "      <td>0.118688</td>\n",
       "      <td>0.061910</td>\n",
       "      <td>0.044924</td>\n",
       "      <td>-0.067158</td>\n",
       "      <td>-0.073745</td>\n",
       "      <td>-0.022742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018516</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.077214</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.128104</td>\n",
       "      <td>-0.131632</td>\n",
       "      <td>-0.027710</td>\n",
       "      <td>0.269085</td>\n",
       "      <td>-0.064869</td>\n",
       "      <td>0.111912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097766</td>\n",
       "      <td>-0.117110</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.074179</td>\n",
       "      <td>0.143129</td>\n",
       "      <td>0.072559</td>\n",
       "      <td>0.055359</td>\n",
       "      <td>-0.080812</td>\n",
       "      <td>-0.093793</td>\n",
       "      <td>-0.030234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013198</td>\n",
       "      <td>-0.014307</td>\n",
       "      <td>0.086592</td>\n",
       "      <td>0.056287</td>\n",
       "      <td>0.138616</td>\n",
       "      <td>-0.117392</td>\n",
       "      <td>-0.037586</td>\n",
       "      <td>0.271665</td>\n",
       "      <td>-0.035025</td>\n",
       "      <td>0.126754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121644</td>\n",
       "      <td>-0.113244</td>\n",
       "      <td>-0.050501</td>\n",
       "      <td>-0.093834</td>\n",
       "      <td>0.085799</td>\n",
       "      <td>0.076067</td>\n",
       "      <td>0.057251</td>\n",
       "      <td>-0.081211</td>\n",
       "      <td>-0.082183</td>\n",
       "      <td>-0.032743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.020882  0.010146  0.074476  0.049863  0.122592 -0.127202 -0.025988   \n",
       "1  0.030421  0.011001  0.073398  0.042254  0.128152 -0.121796 -0.026794   \n",
       "2  0.026502  0.008255  0.064975  0.039736  0.108406 -0.111629 -0.027741   \n",
       "3  0.018516  0.010517  0.077214  0.051298  0.128104 -0.131632 -0.027710   \n",
       "4  0.013198 -0.014307  0.086592  0.056287  0.138616 -0.117392 -0.037586   \n",
       "\n",
       "          7         8         9  ...       190       191       192       193  \\\n",
       "0  0.255989 -0.063943  0.106702  ...  0.094013 -0.115644  0.007459 -0.069337   \n",
       "1  0.244542 -0.053698  0.107955  ...  0.089291 -0.101986 -0.007420 -0.068880   \n",
       "2  0.211317 -0.047374  0.098843  ...  0.076891 -0.087726 -0.007771 -0.060584   \n",
       "3  0.269085 -0.064869  0.111912  ...  0.097766 -0.117110 -0.000688 -0.074179   \n",
       "4  0.271665 -0.035025  0.126754  ...  0.121644 -0.113244 -0.050501 -0.093834   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.146214  0.070044  0.053953 -0.078277 -0.090076 -0.027871  \n",
       "1  0.131901  0.070164  0.055305 -0.077764 -0.083086 -0.025791  \n",
       "2  0.118688  0.061910  0.044924 -0.067158 -0.073745 -0.022742  \n",
       "3  0.143129  0.072559  0.055359 -0.080812 -0.093793 -0.030234  \n",
       "4  0.085799  0.076067  0.057251 -0.081211 -0.082183 -0.032743  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_train_filename = OUTPUT_FOLDER + 'word2vec_train_' + str(200) + '.csv'\n",
    "word2vec_train_df = create_file(word2vec_train_filename, word2vec_model_file, x_train)\n",
    "print(word2vec_train_df.shape)\n",
    "word2vec_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 200)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0.044262</td>\n",
       "      <td>0.128775</td>\n",
       "      <td>-0.130777</td>\n",
       "      <td>-0.033468</td>\n",
       "      <td>0.244803</td>\n",
       "      <td>-0.051639</td>\n",
       "      <td>0.109792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093495</td>\n",
       "      <td>-0.106990</td>\n",
       "      <td>-0.006401</td>\n",
       "      <td>-0.063361</td>\n",
       "      <td>0.131392</td>\n",
       "      <td>0.068798</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>-0.075939</td>\n",
       "      <td>-0.087870</td>\n",
       "      <td>-0.026534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019942</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.078289</td>\n",
       "      <td>0.054520</td>\n",
       "      <td>0.124541</td>\n",
       "      <td>-0.122664</td>\n",
       "      <td>-0.029338</td>\n",
       "      <td>0.251487</td>\n",
       "      <td>-0.050012</td>\n",
       "      <td>0.114454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099729</td>\n",
       "      <td>-0.114120</td>\n",
       "      <td>-0.012928</td>\n",
       "      <td>-0.073292</td>\n",
       "      <td>0.122156</td>\n",
       "      <td>0.071235</td>\n",
       "      <td>0.052237</td>\n",
       "      <td>-0.079490</td>\n",
       "      <td>-0.083768</td>\n",
       "      <td>-0.028576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054947</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>0.053978</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.139769</td>\n",
       "      <td>-0.160743</td>\n",
       "      <td>-0.030389</td>\n",
       "      <td>0.266557</td>\n",
       "      <td>-0.057817</td>\n",
       "      <td>0.081011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072207</td>\n",
       "      <td>-0.071787</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>-0.065455</td>\n",
       "      <td>0.173246</td>\n",
       "      <td>0.077635</td>\n",
       "      <td>0.075101</td>\n",
       "      <td>-0.088403</td>\n",
       "      <td>-0.089713</td>\n",
       "      <td>-0.022631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.049917</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.056204</td>\n",
       "      <td>0.027117</td>\n",
       "      <td>0.129673</td>\n",
       "      <td>-0.141489</td>\n",
       "      <td>-0.022100</td>\n",
       "      <td>0.249026</td>\n",
       "      <td>-0.049515</td>\n",
       "      <td>0.088030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081327</td>\n",
       "      <td>-0.079331</td>\n",
       "      <td>-0.008764</td>\n",
       "      <td>-0.065936</td>\n",
       "      <td>0.153854</td>\n",
       "      <td>0.073913</td>\n",
       "      <td>0.069424</td>\n",
       "      <td>-0.080221</td>\n",
       "      <td>-0.085031</td>\n",
       "      <td>-0.029760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.060072</td>\n",
       "      <td>0.031912</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>-0.122264</td>\n",
       "      <td>-0.025206</td>\n",
       "      <td>0.222788</td>\n",
       "      <td>-0.049385</td>\n",
       "      <td>0.087883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075618</td>\n",
       "      <td>-0.084216</td>\n",
       "      <td>-0.003909</td>\n",
       "      <td>-0.061549</td>\n",
       "      <td>0.132866</td>\n",
       "      <td>0.063816</td>\n",
       "      <td>0.050377</td>\n",
       "      <td>-0.071298</td>\n",
       "      <td>-0.076210</td>\n",
       "      <td>-0.024081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.026803  0.010217  0.076619  0.044262  0.128775 -0.130777 -0.033468   \n",
       "1  0.019942  0.005275  0.078289  0.054520  0.124541 -0.122664 -0.029338   \n",
       "2  0.054947  0.055499  0.053978  0.021544  0.139769 -0.160743 -0.030389   \n",
       "3  0.049917  0.028666  0.056204  0.027117  0.129673 -0.141489 -0.022100   \n",
       "4  0.032248  0.017993  0.060072  0.031912  0.113800 -0.122264 -0.025206   \n",
       "\n",
       "          7         8         9  ...       190       191       192       193  \\\n",
       "0  0.244803 -0.051639  0.109792  ...  0.093495 -0.106990 -0.006401 -0.063361   \n",
       "1  0.251487 -0.050012  0.114454  ...  0.099729 -0.114120 -0.012928 -0.073292   \n",
       "2  0.266557 -0.057817  0.081011  ...  0.072207 -0.071787  0.000779 -0.065455   \n",
       "3  0.249026 -0.049515  0.088030  ...  0.081327 -0.079331 -0.008764 -0.065936   \n",
       "4  0.222788 -0.049385  0.087883  ...  0.075618 -0.084216 -0.003909 -0.061549   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.131392  0.068798  0.047431 -0.075939 -0.087870 -0.026534  \n",
       "1  0.122156  0.071235  0.052237 -0.079490 -0.083768 -0.028576  \n",
       "2  0.173246  0.077635  0.075101 -0.088403 -0.089713 -0.022631  \n",
       "3  0.153854  0.073913  0.069424 -0.080221 -0.085031 -0.029760  \n",
       "4  0.132866  0.063816  0.050377 -0.071298 -0.076210 -0.024081  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_test_filename = OUTPUT_FOLDER + 'word2vec_test_' + str(200) + '.csv'\n",
    "word2vec_test_df = create_file(word2vec_test_filename, word2vec_model_file, x_test)\n",
    "print(word2vec_test_df.shape)\n",
    "word2vec_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "\n",
    "word2vec_train_scaled_df = pd.DataFrame(mm.fit_transform(word2vec_train_df))\n",
    "word2vec_test_scaled_df = pd.DataFrame(mm.fit_transform(word2vec_test_df))\n",
    "\n",
    "word2vec_train_scaled_df.head()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train_scaled = le.fit_transform(y_train['avg_sentiment'])\n",
    "y_test_scaled = le.fit_transform(y_test['avg_sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 0.05437898635864258\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_decision_word2vec = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model\n",
    "clf_decision_word2vec.fit(word2vec_train_df, y_train['avg_sentiment'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.09      0.15        56\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.64      0.95      0.76       114\n",
      "\n",
      "    accuracy                           0.62       182\n",
      "   macro avg       0.36      0.35      0.30       182\n",
      "weighted avg       0.54      0.62      0.52       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "        \n",
    "y_pred_word2vec = clf_decision_word2vec.predict(word2vec_test_df)\n",
    "print(classification_report(y_test['avg_sentiment'], y_pred_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6052941176470588"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_pipe = Pipeline([('mms', MinMaxScaler()),\n",
    "                    ('dt', DecisionTreeClassifier())])\n",
    "params = [{\n",
    "    'dt__criterion':['gini', 'entropy'],\n",
    "    'dt__max_depth':[3, 5, 7, 9, 11],\n",
    "    'dt__random_state':[42]\n",
    "}]\n",
    "\n",
    "dt_pipe.get_params().keys()\n",
    "gs_dt = GridSearchCV(dt_pipe,\n",
    "                    param_grid=params,\n",
    "                    scoring='accuracy',\n",
    "                    cv=5)\n",
    "gs_dt.fit(word2vec_train_df, y_train['avg_sentiment'])\n",
    "gs_dt.best_params_\n",
    "gs_dt.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 1.9543437957763672\n"
     ]
    }
   ],
   "source": [
    "clf_random_word2vec = RandomForestClassifier(n_estimators=300, criterion='entropy', max_depth=9, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "clf_random_word2vec.fit(word2vec_train_df, y_train['avg_sentiment'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.09      0.15        56\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.64      0.95      0.76       114\n",
      "\n",
      "    accuracy                           0.62       182\n",
      "   macro avg       0.36      0.35      0.30       182\n",
      "weighted avg       0.54      0.62      0.52       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_word2vec = clf_decision_word2vec.predict(word2vec_test_df)\n",
    "print(classification_report(y_test['avg_sentiment'], y_pred_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6312605042016807"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pipe = Pipeline([('mms', MinMaxScaler()),\n",
    "                    ('rfc', RandomForestClassifier())])\n",
    "params = [{\n",
    "    'rfc__n_estimators':[50, 75, 100, 200, 300],\n",
    "    'rfc__criterion':['gini', 'entropy'],\n",
    "    'rfc__max_depth':[3, 5, 7, 9, 11],\n",
    "    'rfc__random_state':[42]\n",
    "}]\n",
    "\n",
    "rfc_pipe.get_params().keys()\n",
    "gs_rfc = GridSearchCV(rfc_pipe,\n",
    "                    param_grid=params,\n",
    "                    scoring='accuracy',\n",
    "                    cv=5)\n",
    "gs_rfc.fit(word2vec_train_df, y_train['avg_sentiment'])\n",
    "gs_rfc.best_params_\n",
    "gs_rfc.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 0.012979984283447266\n"
     ]
    }
   ],
   "source": [
    "clf_multinomial_nb_word2vec = MultinomialNB()\n",
    "\n",
    "start_time = time.time()\n",
    "clf_multinomial_nb_word2vec.fit(word2vec_train_scaled_df, y_train['avg_sentiment'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.45      0.09      0.15        56\n",
      "           0       0.00      0.00      0.00        12\n",
      "           1       0.64      0.95      0.76       114\n",
      "\n",
      "    accuracy                           0.62       182\n",
      "   macro avg       0.36      0.35      0.30       182\n",
      "weighted avg       0.54      0.62      0.52       182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_word2vec = clf_decision_word2vec.predict(word2vec_test_df)\n",
    "print(classification_report(y_test['avg_sentiment'], y_pred_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6004761904761905"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_pipe = Pipeline([('mms', MinMaxScaler()),\n",
    "                    ('mnb', MultinomialNB())])\n",
    "params = [{\n",
    "    'mnb__fit_prior':[True, False]\n",
    "}]\n",
    "\n",
    "mnb_pipe.get_params().keys()\n",
    "gs_mnb = GridSearchCV(mnb_pipe,\n",
    "                    param_grid=params,\n",
    "                    scoring='accuracy',\n",
    "                    cv=5)\n",
    "gs_mnb.fit(word2vec_train_df, y_train['avg_sentiment'])\n",
    "gs_mnb.best_params_\n",
    "gs_mnb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
