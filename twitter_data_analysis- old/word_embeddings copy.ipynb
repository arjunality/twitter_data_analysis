{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import time\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('/Users/arjunkhanchandani/Desktop/twitter_data_analysis-main/data/final_manual_priority.csv')\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S.no.</th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>twt_created_at</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>nltk_compound</th>\n",
       "      <th>avg_sentiment</th>\n",
       "      <th>textblob_sentiment</th>\n",
       "      <th>nltk_sentiment</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>UtkarshMishra_9</td>\n",
       "      <td>Noida, India</td>\n",
       "      <td>707</td>\n",
       "      <td>1122</td>\n",
       "      <td>2022-11-08 21:14:55+00:00</td>\n",
       "      <td>5764</td>\n",
       "      <td>0</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>[{'text': 'earthquake', 'indices': [137, 148]}...</td>\n",
       "      <td>[{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>GirjeshKPatel</td>\n",
       "      <td>‚Ä°¬ß‚â§‚Ä°¬ß√±‚Ä°¬ß¬Æ‚Ä°¬ß√§, ‚Ä°¬ß‚â†‚Ä°¬ß√¶...</td>\n",
       "      <td>164</td>\n",
       "      <td>988</td>\n",
       "      <td>2022-11-08 20:54:48+00:00</td>\n",
       "      <td>522</td>\n",
       "      <td>0</td>\n",
       "      <td>heavy roorke uttrakhand second horrible moment</td>\n",
       "      <td>[{'text': 'earthquake', 'indices': [6, 17]}]</td>\n",
       "      <td>[{'screen_name': 'ZeeNews', 'name': 'Zee News'...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.5423</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>TheAnantpandit</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>409</td>\n",
       "      <td>19</td>\n",
       "      <td>2022-11-08 20:46:16+00:00</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake magnitude occurred ist lat long dep...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'Indiametdept', 'name': 'Indi...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>kanhagupta21</td>\n",
       "      <td>Allahabad</td>\n",
       "      <td>182</td>\n",
       "      <td>13</td>\n",
       "      <td>2022-11-08 20:38:44+00:00</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>horrible ended running outside home safe</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.1531</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>Kunalgupta_voi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-08 20:10:38+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>choking wakeup antismog gun installed watering...</td>\n",
       "      <td>[{'text': 'DelhiPollution', 'indices': [253, 2...</td>\n",
       "      <td>[{'screen_name': 'ArvindKejriwal', 'name': 'Ar...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.6597</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S.no.  user_id  tweet_id         username  \\\n",
       "0      4       11        11  UtkarshMishra_9   \n",
       "1      8       18        18    GirjeshKPatel   \n",
       "2     10       25        25   TheAnantpandit   \n",
       "3     11       31        31     kanhagupta21   \n",
       "4     13       42        42   Kunalgupta_voi   \n",
       "\n",
       "                                            location  following  followers  \\\n",
       "0                                       Noida, India        707       1122   \n",
       "1  ‚Ä°¬ß‚â§‚Ä°¬ß√±‚Ä°¬ß¬Æ‚Ä°¬ß√§, ‚Ä°¬ß‚â†‚Ä°¬ß√¶...        164        988   \n",
       "2                                   New Delhi, India        409         19   \n",
       "3                                          Allahabad        182         13   \n",
       "4                                                NaN         21          1   \n",
       "\n",
       "              twt_created_at  total_tweets  retweet_count  \\\n",
       "0  2022-11-08 21:14:55+00:00          5764              0   \n",
       "1  2022-11-08 20:54:48+00:00           522              0   \n",
       "2  2022-11-08 20:46:16+00:00           152              0   \n",
       "3  2022-11-08 20:38:44+00:00            73              0   \n",
       "4  2022-11-08 20:10:38+00:00             1              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  estimated magnitude earthquake affected countr...   \n",
       "1     heavy roorke uttrakhand second horrible moment   \n",
       "2  earthquake magnitude occurred ist lat long dep...   \n",
       "3           horrible ended running outside home safe   \n",
       "4  choking wakeup antismog gun installed watering...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'earthquake', 'indices': [137, 148]}...   \n",
       "1       [{'text': 'earthquake', 'indices': [6, 17]}]   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4  [{'text': 'DelhiPollution', 'indices': [253, 2...   \n",
       "\n",
       "                                            mentions  textblob_polarity  \\\n",
       "0  [{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...           0.000000   \n",
       "1  [{'screen_name': 'ZeeNews', 'name': 'Zee News'...          -0.400000   \n",
       "2  [{'screen_name': 'Indiametdept', 'name': 'Indi...          -0.050000   \n",
       "3  [{'screen_name': 'ANI', 'name': 'ANI', 'id': 3...          -0.166667   \n",
       "4  [{'screen_name': 'ArvindKejriwal', 'name': 'Ar...           0.000000   \n",
       "\n",
       "   nltk_compound  avg_sentiment  textblob_sentiment  nltk_sentiment  priority  \n",
       "0        -0.1531             -1                   0              -1         0  \n",
       "1        -0.5423             -1                  -1              -1         1  \n",
       "2         0.0000             -1                  -1               0         0  \n",
       "3        -0.1531             -1                  -1              -1         1  \n",
       "4        -0.6597             -1                   0              -1         1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping user_id, username, location, following, followers, twt_created_at, total_tweets, retweet_count, hashtags, mentions, tweet_id_dup\n",
    "tweets_df.drop(['S.no.', 'user_id', 'username', 'location', 'following', 'followers', 'twt_created_at', 'total_tweets', 'retweet_count', 'hashtags', 'mentions', 'textblob_polarity', 'nltk_compound', 'textblob_sentiment', 'nltk_sentiment', 'avg_sentiment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'text', 'priority'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>priority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>heavy roorke uttrakhand second horrible moment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>earthquake magnitude occurred ist lat long dep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>horrible ended running outside home safe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>choking wakeup antismog gun installed watering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  priority\n",
       "0        11  estimated magnitude earthquake affected countr...         0\n",
       "1        18     heavy roorke uttrakhand second horrible moment         1\n",
       "2        25  earthquake magnitude occurred ist lat long dep...         0\n",
       "3        31           horrible ended running outside home safe         1\n",
       "4        42  choking wakeup antismog gun installed watering...         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    109\n",
       "0     89\n",
       "Name: priority, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['priority'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_tokens(df):\n",
    "    tokens = list()\n",
    "    tokenizer = TweetTokenizer()\n",
    "    \n",
    "    for tweets in df.loc[:, 'text']:\n",
    "        # print(len(tokenizer.tokenize(tweets)))\n",
    "        tokens.append(tokenizer.tokenize(tweets))\n",
    "    \n",
    "    df['tokens'] = tokens\n",
    "    \n",
    "    porter_stemmer = PorterStemmer()\n",
    "    # Get the stemmed_tokens\n",
    "    df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df['tokens']]\n",
    "    df['stemmed_tokens'].head(10)\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>priority</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>estimated magnitude earthquake affected countr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[estimated, magnitude, earthquake, affected, c...</td>\n",
       "      <td>[estim, magnitud, earthquak, affect, countri, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>heavy roorke uttrakhand second horrible moment</td>\n",
       "      <td>1</td>\n",
       "      <td>[heavy, roorke, uttrakhand, second, horrible, ...</td>\n",
       "      <td>[heavi, roork, uttrakhand, second, horribl, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>earthquake magnitude occurred ist lat long dep...</td>\n",
       "      <td>0</td>\n",
       "      <td>[earthquake, magnitude, occurred, ist, lat, lo...</td>\n",
       "      <td>[earthquak, magnitud, occur, ist, lat, long, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>horrible ended running outside home safe</td>\n",
       "      <td>1</td>\n",
       "      <td>[horrible, ended, running, outside, home, safe]</td>\n",
       "      <td>[horribl, end, run, outsid, home, safe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>choking wakeup antismog gun installed watering...</td>\n",
       "      <td>1</td>\n",
       "      <td>[choking, wakeup, antismog, gun, installed, wa...</td>\n",
       "      <td>[choke, wakeup, antismog, gun, instal, water, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                                               text  priority  \\\n",
       "0        11  estimated magnitude earthquake affected countr...         0   \n",
       "1        18     heavy roorke uttrakhand second horrible moment         1   \n",
       "2        25  earthquake magnitude occurred ist lat long dep...         0   \n",
       "3        31           horrible ended running outside home safe         1   \n",
       "4        42  choking wakeup antismog gun installed watering...         1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [estimated, magnitude, earthquake, affected, c...   \n",
       "1  [heavy, roorke, uttrakhand, second, horrible, ...   \n",
       "2  [earthquake, magnitude, occurred, ist, lat, lo...   \n",
       "3    [horrible, ended, running, outside, home, safe]   \n",
       "4  [choking, wakeup, antismog, gun, installed, wa...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  [estim, magnitud, earthquak, affect, countri, ...  \n",
       "1  [heavi, roork, uttrakhand, second, horribl, mo...  \n",
       "2  [earthquak, magnitud, occur, ist, lat, long, d...  \n",
       "3            [horribl, end, run, outsid, home, safe]  \n",
       "4  [choke, wakeup, antismog, gun, instal, water, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = creating_tokens(tweets_df)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(df, test_size):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df['stemmed_tokens'], df['priority'], test_size=test_size, random_state=42, stratify=df['priority'])\n",
    "    \n",
    "    print(y_train.value_counts())\n",
    "    print(y_test.value_counts())\n",
    "    # print(type(x_train))\n",
    "    # print(type(y_train))\n",
    "    \n",
    "    x_train = x_train.to_frame()\n",
    "    x_train = x_train.reset_index()\n",
    "    \n",
    "    x_test = x_test.to_frame()\n",
    "    x_test = x_test.reset_index()\n",
    "    \n",
    "    y_train = y_train.to_frame()\n",
    "    y_train = y_train.reset_index()\n",
    "    \n",
    "    y_test = y_test.to_frame()\n",
    "    y_test = y_test.reset_index()\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    76\n",
      "0    62\n",
      "Name: priority, dtype: int64\n",
      "1    33\n",
      "0    27\n",
      "Name: priority, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = split_data(tweets_df, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index                                     stemmed_tokens\n",
      "0    164  [forgiv, rapist, murder, cruel, enter, mandir,...\n",
      "1     36  [socha, puch, illeg, resort, demolish, still, ...\n",
      "2     92  [todai, whole, year, complet, dai, written, pa...\n",
      "3     42  [see, ground, realiti, statu, sardar, pathet, ...\n",
      "4     50  [dirti, monei, aap, need, investig, lie, detec...\n",
      "   index                                     stemmed_tokens\n",
      "0    188  [hai, chor, sath, deta, hai, pich, leta, hai, ...\n",
      "1     23  [travel, pass, markundi, toll, acp, toll, pvt,...\n",
      "2    174  [final, todai, yet, mcd, remov, broken, bench,...\n",
      "3     73  [crore, public, monei, invest, project, clean,...\n",
      "4    152  [histor, judgement, suprem, court, put, stamp,...\n",
      "   index  priority\n",
      "0    164         0\n",
      "1     36         0\n",
      "2     92         0\n",
      "3     42         1\n",
      "4     50         0\n",
      "   index  priority\n",
      "0    188         1\n",
      "1     23         1\n",
      "2    174         0\n",
      "3     73         1\n",
      "4    152         0\n"
     ]
    }
   ],
   "source": [
    "print(x_train.head())\n",
    "print(x_test.head())\n",
    "print(y_train.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 2.043767213821411\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "OUTPUT_FOLDER = '/Users/arjunkhanchandani/Desktop/twitter_data_analysis-main'\n",
    "\n",
    "start_time = time.time()\n",
    "tokens = pd.Series(tweets_df['stemmed_tokens']).values\n",
    "# print(tokens)\n",
    "word2vec_model_file = OUTPUT_FOLDER + 'word2vec_' + str(8000) + '.model'\n",
    "\n",
    "w2v_model = Word2Vec(tokens, min_count=1, vector_size=8000, window=8, workers=7, sg=3)\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\n",
    "w2v_model.save(word2vec_model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(create_file, model_file, x):\n",
    "    sg_w2v_model = Word2Vec.load(model_file)\n",
    "    \n",
    "    with open(create_file, 'w+') as word2vec_file:\n",
    "        for index, row in x.iterrows():\n",
    "            model_vector = (np.mean([sg_w2v_model.wv[token] for token in row['stemmed_tokens']], axis=0)).tolist()\n",
    "            if index == 0:\n",
    "                header = \",\".join(str(ele) for ele in range(8000))\n",
    "                word2vec_file.write(header)\n",
    "                word2vec_file.write(\"\\n\")\n",
    "            \n",
    "            if type(model_vector) is list:\n",
    "                line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "            else:\n",
    "                line1 = \",\".join([str(0) for i in range(8000)])\n",
    "            word2vec_file.write(line1)\n",
    "            word2vec_file.write('\\n')\n",
    "    \n",
    "    df = pd.read_csv(create_file)\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 8000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7990</th>\n",
       "      <th>7991</th>\n",
       "      <th>7992</th>\n",
       "      <th>7993</th>\n",
       "      <th>7994</th>\n",
       "      <th>7995</th>\n",
       "      <th>7996</th>\n",
       "      <th>7997</th>\n",
       "      <th>7998</th>\n",
       "      <th>7999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000089</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000128</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.000100</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000126</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000162</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000089 -0.000029  0.000008 -0.000039 -0.000002  0.000010 -0.000026   \n",
       "1  0.000128 -0.000029  0.000025 -0.000022  0.000047 -0.000011 -0.000050   \n",
       "2  0.000156 -0.000052  0.000052 -0.000100  0.000077  0.000019 -0.000046   \n",
       "3  0.000126 -0.000062  0.000037 -0.000113  0.000067  0.000014 -0.000051   \n",
       "4  0.000162 -0.000078  0.000076 -0.000148  0.000059  0.000013 -0.000082   \n",
       "\n",
       "          7         8         9  ...      7990      7991      7992      7993  \\\n",
       "0  0.000036  0.000017  0.000002  ...  0.000022 -0.000019  0.000005 -0.000043   \n",
       "1  0.000009  0.000059 -0.000004  ...  0.000048 -0.000059  0.000061  0.000005   \n",
       "2  0.000057  0.000119 -0.000003  ...  0.000065 -0.000115  0.000022 -0.000026   \n",
       "3  0.000020  0.000090  0.000007  ...  0.000031 -0.000109  0.000037  0.000007   \n",
       "4  0.000065  0.000126  0.000032  ...  0.000070 -0.000098  0.000073 -0.000042   \n",
       "\n",
       "       7994      7995      7996      7997      7998      7999  \n",
       "0 -0.000031  0.000013 -0.000023  0.000027  0.000004  0.000039  \n",
       "1 -0.000022  0.000035 -0.000026 -0.000006 -0.000008  0.000018  \n",
       "2 -0.000069 -0.000035 -0.000034 -0.000002 -0.000045  0.000075  \n",
       "3 -0.000044 -0.000024 -0.000029  0.000023 -0.000022  0.000047  \n",
       "4 -0.000030 -0.000046 -0.000076 -0.000028 -0.000011  0.000069  \n",
       "\n",
       "[5 rows x 8000 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_train_filename = OUTPUT_FOLDER + 'word2vec_train_' + str(8000) + '.csv'\n",
    "word2vec_train_df = create_file(word2vec_train_filename, word2vec_model_file, x_train)\n",
    "print(word2vec_train_df.shape)\n",
    "word2vec_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 8000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7990</th>\n",
       "      <th>7991</th>\n",
       "      <th>7992</th>\n",
       "      <th>7993</th>\n",
       "      <th>7994</th>\n",
       "      <th>7995</th>\n",
       "      <th>7996</th>\n",
       "      <th>7997</th>\n",
       "      <th>7998</th>\n",
       "      <th>7999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000147</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000084</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000154 -0.000046  0.000069 -0.000102  0.000052  0.000031 -0.000050   \n",
       "1  0.000093 -0.000040  0.000026 -0.000109  0.000053  0.000010 -0.000032   \n",
       "2  0.000133 -0.000027  0.000045 -0.000042  0.000026  0.000037 -0.000020   \n",
       "3  0.000147 -0.000069  0.000058 -0.000068  0.000103  0.000017 -0.000030   \n",
       "4  0.000084 -0.000044  0.000008 -0.000054  0.000006  0.000022 -0.000055   \n",
       "\n",
       "          7         8         9  ...      7990      7991      7992      7993  \\\n",
       "0  0.000059  0.000134  0.000038  ...  0.000087 -0.000155  0.000067 -0.000044   \n",
       "1  0.000047  0.000063  0.000015  ...  0.000064 -0.000091  0.000028 -0.000032   \n",
       "2  0.000031  0.000057  0.000035  ...  0.000056 -0.000066  0.000064 -0.000028   \n",
       "3  0.000063  0.000095  0.000006  ...  0.000066 -0.000133  0.000075 -0.000003   \n",
       "4  0.000014  0.000120  0.000002  ...  0.000043 -0.000103  0.000042 -0.000038   \n",
       "\n",
       "       7994      7995      7996      7997      7998      7999  \n",
       "0 -0.000040  0.000006 -0.000057 -0.000041  0.000011  0.000108  \n",
       "1 -0.000030 -0.000006 -0.000021 -0.000025  0.000017  0.000093  \n",
       "2 -0.000012 -0.000015 -0.000035 -0.000042  0.000008  0.000079  \n",
       "3 -0.000052 -0.000023 -0.000023 -0.000033 -0.000029  0.000035  \n",
       "4 -0.000054  0.000003 -0.000038  0.000007 -0.000038  0.000078  \n",
       "\n",
       "[5 rows x 8000 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_test_filename = OUTPUT_FOLDER + 'word2vec_test_' + str(8000) + '.csv'\n",
    "word2vec_test_df = create_file(word2vec_test_filename, word2vec_model_file, x_test)\n",
    "print(word2vec_test_df.shape)\n",
    "word2vec_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138, 2)\n",
      "(60, 2)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to fit the model with word2vec vectors: 0.2762019634246826\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "clf_decision_word2vec = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "# Fit the model\n",
    "clf_decision_word2vec.fit(word2vec_train_df, y_train['priority'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61        27\n",
      "           1       0.68      0.64      0.66        33\n",
      "\n",
      "    accuracy                           0.63        60\n",
      "   macro avg       0.63      0.63      0.63        60\n",
      "weighted avg       0.64      0.63      0.63        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "        \n",
    "y_pred_word2vec = clf_decision_word2vec.predict(word2vec_test_df)\n",
    "print(classification_report(y_test['priority'], y_pred_word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwitu6WthJ77AhX_TmwGHYzTBjMQFnoECBcQAQ&url=https%3A%2F%2Fmedium.com%2F%40zafaralibagh6%2Fa-simple-word2vec-tutorial-61e64e38a6a1&usg=AOvVaw3tHKEk24OxG_LwAiMr2wZs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
