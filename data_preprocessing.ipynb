{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nitanshjain/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/nitanshjain/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/nitanshjain/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import fnmatch\n",
    "import string\n",
    "from urllib.parse import urlparse\n",
    "import contractions\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('words')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import words, stopwords\n",
    "from nltk.metrics.distance import jaccard_distance, edit_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>twt_created_at</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "      <th>tweet_id_dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.334197e+07</td>\n",
       "      <td>1.589270e+18</td>\n",
       "      <td>ravi4354</td>\n",
       "      <td>India,Not in Hindu Rashtra</td>\n",
       "      <td>634</td>\n",
       "      <td>6419</td>\n",
       "      <td>2022-11-06 15:05:20+00:00</td>\n",
       "      <td>41202</td>\n",
       "      <td>0</td>\n",
       "      <td>This is the Goodwill earned by Mr @narendramod...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'narendramodi', 'name': 'Nare...</td>\n",
       "      <td>1.589273e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.046310e+17</td>\n",
       "      <td>1.589270e+18</td>\n",
       "      <td>iamanshulthakur</td>\n",
       "      <td>सिवनी,मध्यप्रदेश,भारत</td>\n",
       "      <td>396</td>\n",
       "      <td>2386</td>\n",
       "      <td>2022-11-06 15:04:52+00:00</td>\n",
       "      <td>9400</td>\n",
       "      <td>0</td>\n",
       "      <td>@PrajwalBusta @narendramodi It's very special ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'PrajwalBusta', 'name': 'Praj...</td>\n",
       "      <td>1.589273e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.113370e+18</td>\n",
       "      <td>1.589270e+18</td>\n",
       "      <td>LifestyleVishnu</td>\n",
       "      <td>Ambikapur, India</td>\n",
       "      <td>304</td>\n",
       "      <td>286</td>\n",
       "      <td>2022-11-06 15:04:46+00:00</td>\n",
       "      <td>5764</td>\n",
       "      <td>0</td>\n",
       "      <td>@AjayHimatlal @YssSpeaks @BJP4Haryana @cmohry ...</td>\n",
       "      <td>[{'text': 'NoActionOnArrestWarrant', 'indices'...</td>\n",
       "      <td>[{'screen_name': 'AjayHimatlal', 'name': 'Ajay...</td>\n",
       "      <td>1.589273e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.249900e+09</td>\n",
       "      <td>1.589270e+18</td>\n",
       "      <td>prkgarg</td>\n",
       "      <td>GLOBE</td>\n",
       "      <td>709</td>\n",
       "      <td>203</td>\n",
       "      <td>2022-11-06 15:04:40+00:00</td>\n",
       "      <td>24799</td>\n",
       "      <td>0</td>\n",
       "      <td>@ArvindKejriwal You will not get more than 2 %...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'ArvindKejriwal', 'name': 'Ar...</td>\n",
       "      <td>1.589273e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.808170e+17</td>\n",
       "      <td>1.589270e+18</td>\n",
       "      <td>SunilBhatM</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>930</td>\n",
       "      <td>2284</td>\n",
       "      <td>2022-11-06 15:04:38+00:00</td>\n",
       "      <td>8235</td>\n",
       "      <td>0</td>\n",
       "      <td>Magnificent!\\n\\nI visited Pradhan Manthri Sang...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'narendramodi', 'name': 'Nare...</td>\n",
       "      <td>1.589273e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id      tweet_id         username                     location  \\\n",
       "0  7.334197e+07  1.589270e+18         ravi4354  India,Not in Hindu Rashtra    \n",
       "1  7.046310e+17  1.589270e+18  iamanshulthakur        सिवनी,मध्यप्रदेश,भारत   \n",
       "2  1.113370e+18  1.589270e+18  LifestyleVishnu             Ambikapur, India   \n",
       "3  2.249900e+09  1.589270e+18          prkgarg                        GLOBE   \n",
       "4  7.808170e+17  1.589270e+18       SunilBhatM             New Delhi, India   \n",
       "\n",
       "   following  followers             twt_created_at  total_tweets  \\\n",
       "0        634       6419  2022-11-06 15:05:20+00:00         41202   \n",
       "1        396       2386  2022-11-06 15:04:52+00:00          9400   \n",
       "2        304        286  2022-11-06 15:04:46+00:00          5764   \n",
       "3        709        203  2022-11-06 15:04:40+00:00         24799   \n",
       "4        930       2284  2022-11-06 15:04:38+00:00          8235   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  This is the Goodwill earned by Mr @narendramod...   \n",
       "1              0  @PrajwalBusta @narendramodi It's very special ...   \n",
       "2              0  @AjayHimatlal @YssSpeaks @BJP4Haryana @cmohry ...   \n",
       "3              0  @ArvindKejriwal You will not get more than 2 %...   \n",
       "4              0  Magnificent!\\n\\nI visited Pradhan Manthri Sang...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'text': 'NoActionOnArrestWarrant', 'indices'...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                            mentions  tweet_id_dup  \n",
       "0  [{'screen_name': 'narendramodi', 'name': 'Nare...  1.589273e+18  \n",
       "1  [{'screen_name': 'PrajwalBusta', 'name': 'Praj...  1.589273e+18  \n",
       "2  [{'screen_name': 'AjayHimatlal', 'name': 'Ajay...  1.589273e+18  \n",
       "3  [{'screen_name': 'ArvindKejriwal', 'name': 'Ar...  1.589273e+18  \n",
       "4  [{'screen_name': 'narendramodi', 'name': 'Nare...  1.589273e+18  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('/Users/nitanshjain/Documents/Thapar 4th Sem/Machine Learing/Machine_Learning_Project/data/20221106_215110_tweets.csv')\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 13)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset before removal of duplicates is (8000, 13)\n",
      "Shape of dataset after removal of duplicates is (2333, 13)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of dataset before removal of duplicates is {}'.format(tweets_df.shape))\n",
    "tweets_df.drop_duplicates(subset=['tweet_id_dup'], inplace=True)\n",
    "print('Shape of dataset after removal of duplicates is {}'.format(tweets_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           float64\n",
       "tweet_id          float64\n",
       "username           object\n",
       "location           object\n",
       "following           int64\n",
       "followers           int64\n",
       "twt_created_at     object\n",
       "total_tweets        int64\n",
       "retweet_count       int64\n",
       "text               object\n",
       "hashtags           object\n",
       "mentions           object\n",
       "tweet_id_dup      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    \"\"\"\n",
    "    One function to rule them all, \n",
    "    one function to find them, \n",
    "    One function to bring them all, \n",
    "    and in the darkness bind them; \n",
    "    \"\"\"\n",
    "    print('Shape of dataset before removal of tweets with less than 5 words is {}'.format(df.shape))\n",
    "    \n",
    "    for tweets in df.loc[:,'text']:\n",
    "        # count+=1\n",
    "        # print(tweets)\n",
    "        tokenizer = TweetTokenizer()\n",
    "        tweet_id = df.loc[df['text'] == tweets, 'tweet_id_dup'].values[0]\n",
    "        # print(tweet_id)\n",
    "        \n",
    "        # removing links\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        x = [word for word in list_words if not urlparse(word).scheme]\n",
    "        tweets = ' '.join(x)\n",
    "\n",
    "        # contractions handling\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        new_list_words = []\n",
    "        for word in list_words:\n",
    "            new_list_words.append(contractions.fix(word))\n",
    "        list_words = new_list_words\n",
    "        del(new_list_words)\n",
    "        tweets = ' '.join(list_words)\n",
    "        \n",
    "        # adding space between words and punctuations\n",
    "        tweets = tweets.replace(',', ' ,').replace('.', ' .').replace('?', ' ?').replace('!', ' !')\n",
    "        \n",
    "        # removing hashtags and mentions\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        list_words = [word for word in list_words if word[0] not in ('#', '@')]\n",
    "        list_words = [word for word in list_words if word[0] not in ('▪')]\n",
    "        tweets = ' '.join(list_words)\n",
    "        \n",
    "        # removing punctuations\n",
    "        tweets = tweets.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        #removing emojis\n",
    "        tweets = re.sub(r'[^\\x00-\\x7F]+', ' ', tweets)\n",
    "        \n",
    "        #lower case\n",
    "        tweets = tweets.lower()\n",
    "        \n",
    "        #remove numbers\n",
    "        tweets = re.sub(r'\\d+', '', tweets)\n",
    "        tweets = re.sub(' +', ' ', tweets)\n",
    "        \n",
    "        #removing stopwords\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        filtered_words = [word for word in list_words if word not in stopwords.words('english')]\n",
    "        tweets = ' '.join(filtered_words)\n",
    "        del(filtered_words)\n",
    "        \n",
    "        #lemmatization\n",
    "        lem = WordNetLemmatizer()\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        for word in list_words:\n",
    "            list_words = list(map(lambda x: x.replace(word, lem.lemmatize(word)), list_words))\n",
    "        tweets = ' '.join(list_words)\n",
    "        \n",
    "        #removing individual letters\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        filtered_words = [word for word in list_words if len(word)>2]\n",
    "        tweets = ' '.join(filtered_words)\n",
    "        del(filtered_words)\n",
    "        \n",
    "        # updating tweets in dataframe\n",
    "        df.loc[df['tweet_id_dup']==tweet_id, 'text'] = tweets\n",
    "        \n",
    "        #remove small tweets\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        if len(list_words) <= 5:\n",
    "            ind_num = df[df['tweet_id_dup']==tweet_id].index\n",
    "            df.drop(ind_num, inplace=True)\n",
    "        # break\n",
    "    print('Shape of dataset after removal of tweets with less than 5 words is {}'.format(df.shape))\n",
    "    \n",
    "    return df\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset before removal of tweets with less than 5 words is (2333, 13)\n",
      "Shape of dataset after removal of tweets with less than 5 words is (1574, 13)\n"
     ]
    }
   ],
   "source": [
    "tweets_df = data_preprocessing(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting tweets_df into a csv file\n",
    "filename = '/Users/nitanshjain/Documents/Thapar 4th Sem/Machine Learing/Machine_Learning_Project/data/tweets_preprocessed_1.csv'\n",
    "tweets_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
