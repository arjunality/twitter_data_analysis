{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues to solve\n",
    "* Far too many duplicates being collected in the dataset\n",
    "* Handle mispelled and redundant words\n",
    "* ~~removing mentions and hashtag~~\n",
    "* ~~removing links, special characters, punctuation marks~~\n",
    "* ~~stopwords removal~~\n",
    "* ~~contractions handling~~\n",
    "* ~~stemming and lemmatization~~ did only lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nitanshjain/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/nitanshjain/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/nitanshjain/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import fnmatch\n",
    "import string\n",
    "from urllib.parse import urlparse\n",
    "import contractions\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('words')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import words, stopwords\n",
    "from nltk.metrics.distance import jaccard_distance, edit_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>username</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>twt_created_at</th>\n",
       "      <th>total_tweets</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.006735e+08</td>\n",
       "      <td>1.585300e+18</td>\n",
       "      <td>sai1951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396</td>\n",
       "      <td>81</td>\n",
       "      <td>2022-10-26 16:04:20+00:00</td>\n",
       "      <td>8226</td>\n",
       "      <td>0</td>\n",
       "      <td>@DHFWKA @PMOIndia @MoHFW_INDIA @CMofKarnataka ...</td>\n",
       "      <td>[{'text': 'Covid_19', 'indices': [392, 401]}, ...</td>\n",
       "      <td>[{'screen_name': 'DHFWKA', 'name': \"K'taka Hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.014309e+08</td>\n",
       "      <td>1.585260e+18</td>\n",
       "      <td>shivaramsingh</td>\n",
       "      <td>Cuttack</td>\n",
       "      <td>777</td>\n",
       "      <td>1242</td>\n",
       "      <td>2022-10-26 13:00:46+00:00</td>\n",
       "      <td>5578</td>\n",
       "      <td>0</td>\n",
       "      <td>@nipun29j @drsuniltaneja @doc_arka @docMPK @sa...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'nipun29j', 'name': 'nipun ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.550427e+09</td>\n",
       "      <td>1.585250e+18</td>\n",
       "      <td>rhltiwari711</td>\n",
       "      <td>Lucknow, India</td>\n",
       "      <td>2573</td>\n",
       "      <td>520</td>\n",
       "      <td>2022-10-26 12:49:43+00:00</td>\n",
       "      <td>4641</td>\n",
       "      <td>0</td>\n",
       "      <td>Dear @TwitterIndia, kindly provide @verified t...</td>\n",
       "      <td>[{'text': 'VC', 'indices': [74, 77]}, {'text':...</td>\n",
       "      <td>[{'screen_name': 'TwitterIndia', 'name': 'Twit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.909045e+08</td>\n",
       "      <td>1.585230e+18</td>\n",
       "      <td>amishradp</td>\n",
       "      <td>दिल्ली, भारत</td>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>2022-10-26 11:26:36+00:00</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>@care_mediassist @royalsundaram @naveen_shahi1...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'care_mediassist', 'name': 'S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.509451e+08</td>\n",
       "      <td>1.585230e+18</td>\n",
       "      <td>chouhanneeraj07</td>\n",
       "      <td>Mumbai, India</td>\n",
       "      <td>879</td>\n",
       "      <td>488</td>\n",
       "      <td>2022-10-26 11:23:47+00:00</td>\n",
       "      <td>3450</td>\n",
       "      <td>0</td>\n",
       "      <td>@drchetandeshmu1 @aparanjape @JM_Scindia @mans...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'drchetandeshmu1', 'name': 'd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id      tweet_id         username        location  following  \\\n",
       "0  1.006735e+08  1.585300e+18          sai1951             NaN        396   \n",
       "1  1.014309e+08  1.585260e+18    shivaramsingh         Cuttack        777   \n",
       "2  1.550427e+09  1.585250e+18     rhltiwari711  Lucknow, India       2573   \n",
       "3  1.909045e+08  1.585230e+18        amishradp    दिल्ली, भारत         51   \n",
       "4  3.509451e+08  1.585230e+18  chouhanneeraj07   Mumbai, India        879   \n",
       "\n",
       "   followers             twt_created_at  total_tweets  retweet_count  \\\n",
       "0         81  2022-10-26 16:04:20+00:00          8226              0   \n",
       "1       1242  2022-10-26 13:00:46+00:00          5578              0   \n",
       "2        520  2022-10-26 12:49:43+00:00          4641              0   \n",
       "3          9  2022-10-26 11:26:36+00:00           243              0   \n",
       "4        488  2022-10-26 11:23:47+00:00          3450              0   \n",
       "\n",
       "                                                text  \\\n",
       "0  @DHFWKA @PMOIndia @MoHFW_INDIA @CMofKarnataka ...   \n",
       "1  @nipun29j @drsuniltaneja @doc_arka @docMPK @sa...   \n",
       "2  Dear @TwitterIndia, kindly provide @verified t...   \n",
       "3  @care_mediassist @royalsundaram @naveen_shahi1...   \n",
       "4  @drchetandeshmu1 @aparanjape @JM_Scindia @mans...   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  [{'text': 'Covid_19', 'indices': [392, 401]}, ...   \n",
       "1                                                 []   \n",
       "2  [{'text': 'VC', 'indices': [74, 77]}, {'text':...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                            mentions  \n",
       "0  [{'screen_name': 'DHFWKA', 'name': \"K'taka Hea...  \n",
       "1  [{'screen_name': 'nipun29j', 'name': 'nipun ve...  \n",
       "2  [{'screen_name': 'TwitterIndia', 'name': 'Twit...  \n",
       "3  [{'screen_name': 'care_mediassist', 'name': 'S...  \n",
       "4  [{'screen_name': 'drchetandeshmu1', 'name': 'd...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv('/Users/nitanshjain/Documents/Thapar 4th Sem/Machine Learing/Machine_Learning_Project/data/20221026_235416_tweets.csv')\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1293, 12)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset before removal of duplicates is (1293, 12)\n",
      "Shape of dataset after removal of duplicates is (139, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of dataset before removal of duplicates is {}'.format(tweets_df.shape))\n",
    "tweets_df.drop_duplicates(subset=['tweet_id'], inplace=True)\n",
    "print('Shape of dataset after removal of duplicates is {}'.format(tweets_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           float64\n",
       "tweet_id          float64\n",
       "username           object\n",
       "location           object\n",
       "following           int64\n",
       "followers           int64\n",
       "twt_created_at     object\n",
       "total_tweets        int64\n",
       "retweet_count       int64\n",
       "text               object\n",
       "hashtags           object\n",
       "mentions           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    count=0\n",
    "    \"\"\"\n",
    "    One function to rule them all, \n",
    "    one function to find them, \n",
    "    One function to bring them all, \n",
    "    and in the darkness bind them; \n",
    "    \"\"\"\n",
    "    print('Shape of dataset before removal of tweets with less than 5 words is {}'.format(df.shape))\n",
    "    \n",
    "    for tweets in df.loc[:,'text']:\n",
    "        # count+=1\n",
    "        # print(tweets)\n",
    "        tokenizer = TweetTokenizer()\n",
    "        tweet_id = df.loc[df['text'] == tweets, 'tweet_id'].values[0] \n",
    "        \n",
    "        # removing links\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        x = [word for word in list_words if not urlparse(word).scheme]\n",
    "        tweets = ' '.join(x)\n",
    "\n",
    "        # contractions handling\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        new_list_words = []\n",
    "        for word in list_words:\n",
    "            new_list_words.append(contractions.fix(word))\n",
    "        list_words = new_list_words\n",
    "        del(new_list_words)\n",
    "        tweets = ' '.join(list_words)\n",
    "        \n",
    "        # adding space between words and punctuations\n",
    "        tweets = tweets.replace(',', ' ,').replace('.', ' .').replace('?', ' ?').replace('!', ' !')\n",
    "        \n",
    "        # removing hashtags and mentions\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        list_words = [word for word in list_words if word[0] not in ('#', '@')]\n",
    "        list_words = [word for word in list_words if word[0] not in ('▪')]\n",
    "        tweets = ' '.join(list_words)\n",
    "        \n",
    "        # removing punctuations\n",
    "        tweets = tweets.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        #removing emojis\n",
    "        tweets = re.sub(r'[^\\x00-\\x7F]+', ' ', tweets)\n",
    "        \n",
    "        #lower case\n",
    "        tweets = tweets.lower()\n",
    "        \n",
    "        #remove numbers\n",
    "        tweets = re.sub(r'\\d+', '', tweets)\n",
    "        tweets = re.sub(' +', ' ', tweets)\n",
    "        \n",
    "        #removing stopwords\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        filtered_words = [word for word in list_words if word not in stopwords.words('english')]\n",
    "        tweets = ' '.join(filtered_words)\n",
    "        del(filtered_words)\n",
    "        \n",
    "        #lemmatization\n",
    "        lem = WordNetLemmatizer()\n",
    "        list_words = word_tokenize(tweets)\n",
    "        for word in list_words:\n",
    "            list_words = list(map(lambda x: x.replace(word, lem.lemmatize(word)), list_words))\n",
    "        tweets = ' '.join(list_words)\n",
    "        \n",
    "        #removing individual letters\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        filtered_words = [word for word in list_words if len(word)>2]\n",
    "        tweets = ' '.join(filtered_words)\n",
    "        del(filtered_words)\n",
    "        \n",
    "        # updating tweets in dataframe\n",
    "        df.loc[df['tweet_id']==tweet_id, 'text'] = tweets\n",
    "        \n",
    "        #remove small tweets\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        if len(list_words) <= 5:\n",
    "            ind_num = df[df['tweet_id']==tweet_id].index\n",
    "            df.drop(ind_num, inplace=True)\n",
    "        # break\n",
    "    print('Shape of dataset after removal of tweets with less than 5 words is {}'.format(df.shape))\n",
    "    \n",
    "    return df\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset before removal of tweets with less than 5 words is (139, 12)\n",
      "Shape of dataset after removal of tweets with less than 5 words is (106, 12)\n"
     ]
    }
   ],
   "source": [
    "tweets_df = data_preprocessing(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correcting_words(df):\n",
    "    tokenizer = TweetTokenizer()\n",
    "    for tweets in df.loc[:, 'text']:\n",
    "        list_words = tokenizer.tokenize(tweets)\n",
    "        correct_words = []\n",
    "        for word in list_words:\n",
    "            temp = [(edit_distance(word, w),w) for w in words.words() if w[0]==word[0] and w[len(w)-1]==word[len(word)-1]]\n",
    "            correct_words.append(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "        print(list_words)\n",
    "        print(correct_words)\n",
    "    \n",
    "    # for i in range(len(df)):\n",
    "    #     words_list = df.loc[i, ('text')].split()\n",
    "    #     for word in words_list:\n",
    "    #         if word not in words.words():\n",
    "    #             # print(word)\n",
    "    #             for w in words.words():\n",
    "    #                 if jaccard_distance(set(ngrams(word, n=3)), set(ngrams(w, n=3))) < 0.5:\n",
    "    #                     # print(w)\n",
    "    #                     ind = words_list.index(word)\n",
    "    #                     words_list[ind] = w\n",
    "    #                     break\n",
    "    #     df.loc[i, ('text')] = ' '.join(words_list)\n",
    "        \n",
    "    #     return df\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
